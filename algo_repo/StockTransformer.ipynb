{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h2>Stock Market Transformer Model</h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from abc import ABC\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot\n",
    "from pytorch_forecasting import TimeSeriesDataSet\n",
    "from pytorch_forecasting.data.encoders import TorchNormalizer\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pytorch_forecasting.models.base_model import BaseModel, BaseModelWithCovariates\n",
    "import matplotlib.pyplot as plt\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3>Data</h3>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print('hi')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/plain": "                Open      High       Low     Close     Volume\nDate                                                         \n1980-12-12  0.100323  0.100759  0.100323  0.100323  469033600\n1980-12-15  0.095525  0.095525  0.095089  0.095089  175884800\n1980-12-16  0.088546  0.088546  0.088110  0.088110  105728000\n1980-12-17  0.090291  0.090727  0.090291  0.090291   86441600\n1980-12-18  0.092908  0.093345  0.092908  0.092908   73449600",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Open</th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Close</th>\n      <th>Volume</th>\n    </tr>\n    <tr>\n      <th>Date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1980-12-12</th>\n      <td>0.100323</td>\n      <td>0.100759</td>\n      <td>0.100323</td>\n      <td>0.100323</td>\n      <td>469033600</td>\n    </tr>\n    <tr>\n      <th>1980-12-15</th>\n      <td>0.095525</td>\n      <td>0.095525</td>\n      <td>0.095089</td>\n      <td>0.095089</td>\n      <td>175884800</td>\n    </tr>\n    <tr>\n      <th>1980-12-16</th>\n      <td>0.088546</td>\n      <td>0.088546</td>\n      <td>0.088110</td>\n      <td>0.088110</td>\n      <td>105728000</td>\n    </tr>\n    <tr>\n      <th>1980-12-17</th>\n      <td>0.090291</td>\n      <td>0.090727</td>\n      <td>0.090291</td>\n      <td>0.090291</td>\n      <td>86441600</td>\n    </tr>\n    <tr>\n      <th>1980-12-18</th>\n      <td>0.092908</td>\n      <td>0.093345</td>\n      <td>0.092908</td>\n      <td>0.092908</td>\n      <td>73449600</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "data = yf.download(tickers=\"AAPL\", period='max', interval='1d', groupby='ticker', auto_adjust='True')\n",
    "data.head()\n",
    "\n",
    "#create random data\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "   order         Date      Open      High       Low     Close     Volume  \\\n0      0  345427200.0  0.100323  0.100759  0.100323  0.100323  469033600   \n1      1  345686400.0  0.095525  0.095525  0.095089  0.095089  175884800   \n2      2  345772800.0  0.088546  0.088546  0.088110  0.088110  105728000   \n3      3  345859200.0  0.090291  0.090727  0.090291  0.090291   86441600   \n4      4  345945600.0  0.092908  0.093345  0.092908  0.092908   73449600   \n\n     Target  \n0  0.095089  \n1  0.088110  \n2  0.090291  \n3  0.092908  \n4  0.098578  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>order</th>\n      <th>Date</th>\n      <th>Open</th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Close</th>\n      <th>Volume</th>\n      <th>Target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>345427200.0</td>\n      <td>0.100323</td>\n      <td>0.100759</td>\n      <td>0.100323</td>\n      <td>0.100323</td>\n      <td>469033600</td>\n      <td>0.095089</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>345686400.0</td>\n      <td>0.095525</td>\n      <td>0.095525</td>\n      <td>0.095089</td>\n      <td>0.095089</td>\n      <td>175884800</td>\n      <td>0.088110</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>345772800.0</td>\n      <td>0.088546</td>\n      <td>0.088546</td>\n      <td>0.088110</td>\n      <td>0.088110</td>\n      <td>105728000</td>\n      <td>0.090291</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>345859200.0</td>\n      <td>0.090291</td>\n      <td>0.090727</td>\n      <td>0.090291</td>\n      <td>0.090291</td>\n      <td>86441600</td>\n      <td>0.092908</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>345945600.0</td>\n      <td>0.092908</td>\n      <td>0.093345</td>\n      <td>0.092908</td>\n      <td>0.092908</td>\n      <td>73449600</td>\n      <td>0.098578</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.reset_index(inplace=True)\n",
    "data.index = data.index.set_names([\"order\"])\n",
    "data.reset_index(inplace=True)#to keep up with order\n",
    "data['Target'] = data[\"Close\"].shift(-1)\n",
    "data[\"Date\"] = data[\"Date\"].apply(lambda x: x.value/10**9)\n",
    "\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "          Date      Open      High       Low     Close     Volume    Target\n0  345427200.0  0.100323  0.100759  0.100323  0.100323  469033600  0.095089\n1  345686400.0  0.095525  0.095525  0.095089  0.095089  175884800  0.088110\n2  345772800.0  0.088546  0.088546  0.088110  0.088110  105728000  0.090291\n3  345859200.0  0.090291  0.090727  0.090291  0.090291   86441600  0.092908\n4  345945600.0  0.092908  0.093345  0.092908  0.092908   73449600  0.098578",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Open</th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Close</th>\n      <th>Volume</th>\n      <th>Target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>345427200.0</td>\n      <td>0.100323</td>\n      <td>0.100759</td>\n      <td>0.100323</td>\n      <td>0.100323</td>\n      <td>469033600</td>\n      <td>0.095089</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>345686400.0</td>\n      <td>0.095525</td>\n      <td>0.095525</td>\n      <td>0.095089</td>\n      <td>0.095089</td>\n      <td>175884800</td>\n      <td>0.088110</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>345772800.0</td>\n      <td>0.088546</td>\n      <td>0.088546</td>\n      <td>0.088110</td>\n      <td>0.088110</td>\n      <td>105728000</td>\n      <td>0.090291</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>345859200.0</td>\n      <td>0.090291</td>\n      <td>0.090727</td>\n      <td>0.090291</td>\n      <td>0.090291</td>\n      <td>86441600</td>\n      <td>0.092908</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>345945600.0</td>\n      <td>0.092908</td>\n      <td>0.093345</td>\n      <td>0.092908</td>\n      <td>0.092908</td>\n      <td>73449600</td>\n      <td>0.098578</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop(columns=['order'], inplace=True)\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = data.drop([\"Target\"], axis=1)\n",
    "y = data[\"Target\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.1, random_state=42, shuffle=False)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from StockDataLoader import StockDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not determine the shape of object type 'DataFrame'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[0;32mIn [8]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0m dataset_train \u001B[38;5;241m=\u001B[39m \u001B[43mStockDataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m30\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m dataset_val \u001B[38;5;241m=\u001B[39m StockDataset(X_val, y_val, \u001B[38;5;241m30\u001B[39m)\n\u001B[1;32m      4\u001B[0m train_dataloader \u001B[38;5;241m=\u001B[39m DataLoader(dataset_train, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m16\u001B[39m, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "File \u001B[0;32m~/Documents/CSC 492/csc492_deep_learning_project/algo_repo/StockDataLoader.py:46\u001B[0m, in \u001B[0;36mStockDataset.__init__\u001B[0;34m(self, x, y, sequence_length)\u001B[0m\n\u001B[1;32m     45\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, x, y, sequence_length):\n\u001B[0;32m---> 46\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mx \u001B[38;5;241m=\u001B[39m \u001B[43mTensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     47\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39my \u001B[38;5;241m=\u001B[39m Tensor(y)\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m'\u001B[39m)  \u001B[38;5;66;03m# shifted close pricgit adde\u001B[39;00m\n\u001B[1;32m     48\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mseq_length \u001B[38;5;241m=\u001B[39m sequence_length\n",
      "\u001B[0;31mValueError\u001B[0m: could not determine the shape of object type 'DataFrame'"
     ]
    }
   ],
   "source": [
    "dataset_train = StockDataset(X_train, y_train, 30)\n",
    "dataset_val = StockDataset(X_val, y_val, 30)\n",
    "\n",
    "train_dataloader = DataLoader(dataset_train, batch_size=16, shuffle=False)\n",
    "val_dataloader = DataLoader(dataset_val, batch_size=16, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3>Verifying the stock architecture</h3>\n",
    "\n",
    "Current goal is to makesure that the transformer architecture works with transformer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import transformer\n",
    "import importlib\n",
    "importlib.reload(transformer)\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, params):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.transf = transformer.TransformerModel(n_layers=params.n_layers,\n",
    "                                                   num_heads=params.num_heads,\n",
    "                                                   model_dim=params.model_dim,\n",
    "                                                   forward_dim=params.forward_dim,\n",
    "                                                   output_dim=16,\n",
    "                                                   dropout=params.dropout)\n",
    "        self.linear = nn.Linear(16, params.output_dim)\n",
    "    def forward(self, x):\n",
    "        transf_out = self.transf(x)\n",
    "        out = self.linear(transf_out)\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def train(model, data, optimizer='adam', batch_size=16, learning_rate=0.1, momentum=0.9, num_epochs=10, weight_decay=0.0):\n",
    "\n",
    "    #create training, valid and test sets of StockDataset type data\n",
    "    train_custom, valid_custom, test_custom= split_data(data)\n",
    "\n",
    "    #create loaders\n",
    "    train_dataloader = DataLoader(train_custom, batch_size=16, shuffle=False) #returns the X and associated y prediction\n",
    "    val_dataloader = DataLoader(valid_custom, batch_size=16, shuffle=False) #does same\n",
    "    valid_iterator = iter(val_dataloader)\n",
    "    optimizer = optim.Adam(model.parameters(),\n",
    "                          lr = learning_rate,\n",
    "                           weight_decay = weight_decay)\n",
    "\n",
    "    #track learning curve\n",
    "    criterion = nn.MSELoss(reduction=\"mean\")\n",
    "    iters, train_losses, val_losses = [], [], []\n",
    "    #train\n",
    "    n = 0\n",
    "    for epoch in range(0, num_epochs):\n",
    "        print(f'Epoch {epoch} training beginning...')\n",
    "        for X,y in iter(train_dataloader):\n",
    "            if len(X) < batch_size:\n",
    "                continue\n",
    "            model.train() #annotate for train\n",
    "            out = model(X)\n",
    "            loss = criterion(out, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            iters.append(n)\n",
    "            train_losses.append(float(loss)) #average loss\n",
    "            print(f'iter{n}')\n",
    "            #predict validation\n",
    "            for X_val, y_val in iter(val_dataloader):\n",
    "\n",
    "                model.eval() #annotate for test\n",
    "                val_out = model(X_val)\n",
    "                val_loss = criterion(val_out, y_val)\n",
    "                val_losses.append(val_loss)\n",
    "\n",
    "            #save steo\n",
    "    print(f'Final Training Loss: {train_losses[-1]}')\n",
    "    print(f'Final Val Accuracy {val_losses}')\n",
    "    #graph loss\n",
    "    plt.title(\"Learning Loss\")\n",
    "    plt.plot(iters, train_losses, label='Train')\n",
    "    plt.plot(iters, val_losses, label='Validation')\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def split_data(data):\n",
    "\n",
    "\n",
    "    X = data.drop([\"Target\"], axis=1)\n",
    "    y = data[\"Target\"]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.1, random_state=42, shuffle=False)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42, shuffle=False)\n",
    "\n",
    "    dataset_train = StockDataset(X_train, y_train, 30)\n",
    "    dataset_val = StockDataset(X_val, y_val, 30)\n",
    "    dataset_test = StockDataset(X_test, y_test, 30)\n",
    "\n",
    "    return dataset_train, dataset_val, dataset_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not determine the shape of object type 'DataFrame'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[0;32mIn [12]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      9\u001B[0m     lr \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.01\u001B[39m\n\u001B[1;32m     10\u001B[0m model\u001B[38;5;241m=\u001B[39mTransformerModel(transf_params)\n\u001B[0;32m---> 11\u001B[0m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[0;32mIn [10]\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(model, data, optimizer, batch_size, learning_rate, momentum, num_epochs, weight_decay)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtrain\u001B[39m(model, data, optimizer\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124madam\u001B[39m\u001B[38;5;124m'\u001B[39m, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m16\u001B[39m, learning_rate\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.1\u001B[39m, momentum\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.9\u001B[39m, num_epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m, weight_decay\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.0\u001B[39m):\n\u001B[1;32m      2\u001B[0m \n\u001B[1;32m      3\u001B[0m     \u001B[38;5;66;03m#create training, valid and test sets of StockDataset type data\u001B[39;00m\n\u001B[0;32m----> 4\u001B[0m     train_custom, valid_custom, test_custom\u001B[38;5;241m=\u001B[39m \u001B[43msplit_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      6\u001B[0m     \u001B[38;5;66;03m#create loaders\u001B[39;00m\n\u001B[1;32m      7\u001B[0m     train_dataloader \u001B[38;5;241m=\u001B[39m DataLoader(train_custom, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m16\u001B[39m, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m) \u001B[38;5;66;03m#returns the X and associated y prediction\u001B[39;00m\n",
      "Input \u001B[0;32mIn [11]\u001B[0m, in \u001B[0;36msplit_data\u001B[0;34m(data)\u001B[0m\n\u001B[1;32m      6\u001B[0m X_train, X_test, y_train, y_test \u001B[38;5;241m=\u001B[39m train_test_split(X,y,test_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.1\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m      7\u001B[0m X_train, X_val, y_train, y_val \u001B[38;5;241m=\u001B[39m train_test_split(X_train, y_train, test_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.1\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m----> 9\u001B[0m dataset_train \u001B[38;5;241m=\u001B[39m \u001B[43mStockDataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m30\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     10\u001B[0m dataset_val \u001B[38;5;241m=\u001B[39m StockDataset(X_val, y_val, \u001B[38;5;241m30\u001B[39m)\n\u001B[1;32m     11\u001B[0m dataset_test \u001B[38;5;241m=\u001B[39m StockDataset(X_test, y_test, \u001B[38;5;241m30\u001B[39m)\n",
      "File \u001B[0;32m~/Documents/CSC 492/csc492_deep_learning_project/algo_repo/StockDataLoader.py:46\u001B[0m, in \u001B[0;36mStockDataset.__init__\u001B[0;34m(self, x, y, sequence_length)\u001B[0m\n\u001B[1;32m     45\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, x, y, sequence_length):\n\u001B[0;32m---> 46\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mx \u001B[38;5;241m=\u001B[39m \u001B[43mTensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     47\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39my \u001B[38;5;241m=\u001B[39m Tensor(y)\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m'\u001B[39m)  \u001B[38;5;66;03m# shifted close pricgit adde\u001B[39;00m\n\u001B[1;32m     48\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mseq_length \u001B[38;5;241m=\u001B[39m sequence_length\n",
      "\u001B[0;31mValueError\u001B[0m: could not determine the shape of object type 'DataFrame'"
     ]
    }
   ],
   "source": [
    "class transf_params:\n",
    "    n_layers = 4\n",
    "    num_heads = 6\n",
    "    model_dim = 6  # nr of features\n",
    "    forward_dim = 2048\n",
    "    output_dim = 1\n",
    "    dropout = 0\n",
    "    n_epochs = 10\n",
    "    lr = 0.01\n",
    "model=TransformerModel(transf_params)\n",
    "train(model, data)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "   date      open        close       high       low    volume       target  \\\n0     1  1.007781  1000.251625  18.274558  2.407656  2.183359  1000.096941   \n1     2  1.117016  1000.096941  18.031064  2.097707  2.656088  1000.609738   \n2     3  0.628731  1000.609738  18.032101  2.005685  2.911216  1000.592810   \n3     4  1.183502  1000.592810  18.675524  2.198044  2.392530  1000.620224   \n4     5  0.803249  1000.620224  18.504008  2.122631  2.426406  1000.624158   \n\n   constant  \n0       1.0  \n1       1.0  \n2       1.0  \n3       1.0  \n4       1.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>open</th>\n      <th>close</th>\n      <th>high</th>\n      <th>low</th>\n      <th>volume</th>\n      <th>target</th>\n      <th>constant</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1.007781</td>\n      <td>1000.251625</td>\n      <td>18.274558</td>\n      <td>2.407656</td>\n      <td>2.183359</td>\n      <td>1000.096941</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1.117016</td>\n      <td>1000.096941</td>\n      <td>18.031064</td>\n      <td>2.097707</td>\n      <td>2.656088</td>\n      <td>1000.609738</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0.628731</td>\n      <td>1000.609738</td>\n      <td>18.032101</td>\n      <td>2.005685</td>\n      <td>2.911216</td>\n      <td>1000.592810</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1.183502</td>\n      <td>1000.592810</td>\n      <td>18.675524</td>\n      <td>2.198044</td>\n      <td>2.392530</td>\n      <td>1000.620224</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0.803249</td>\n      <td>1000.620224</td>\n      <td>18.504008</td>\n      <td>2.122631</td>\n      <td>2.426406</td>\n      <td>1000.624158</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_timeseries = pd.DataFrame(\n",
    "    dict(\n",
    "    date=[x for x in range(1,2001)],\n",
    "    open=np.random.rand(2000) + 0.2,\n",
    "    close=np.random.rand(2000) + 1000,\n",
    "        high=np.random.rand(2000) + 18,\n",
    "        low = np.random.rand(2000) + 2,\n",
    "        volume=np.random.rand(2000) + 2\n",
    "    ))\n",
    "random_timeseries[\"target\"] = random_timeseries.close.shift(-1)\n",
    "random_timeseries.fillna(3, inplace=True)\n",
    "random_timeseries[\"constant\"] = np.ones(2000)\n",
    "random_timeseries.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "#what features constitute a single timeseries sample\n",
    "group_ids = ['constant']\n",
    "target='target'\n",
    "time_idx = 'date'\n",
    "\n",
    "max_prediction_length=1 #one day\n",
    "#list of continous variables that change over time and are not known in the future\n",
    "time_varying_unknown_reals = ['open', 'close', 'high', 'low', 'volume', 'target']\n",
    "#normalizer, add later\n",
    "#target_normalizer= TorchNormalizer()\n",
    "max_encoder_length = 5\n",
    "min_encoder_length = 0\n",
    "\n",
    "#add no\n",
    "pytorch_random_dataset = TimeSeriesDataSet(random_timeseries,\n",
    "                                           group_ids=group_ids,\n",
    "                                           time_idx=time_idx,\n",
    "                                           target=target,\n",
    "                                           min_prediction_length=1,\n",
    "                                           max_prediction_length=max_prediction_length,\n",
    "                                           max_encoder_length=max_encoder_length,\n",
    "                                           min_encoder_length=min_encoder_length,\n",
    "                                           allow_missing_timesteps=True,\n",
    "                                           time_varying_unknown_reals=time_varying_unknown_reals,\n",
    "                                           #target_normalizer=target_normalizer\n",
    "                                           )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "#check out dataloader which we will use to feed data to the model's forward method\n",
    "data_loader = pytorch_random_dataset.to_dataloader(batch_size=16, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kagema/anaconda3/envs/csc492_v2/lib/python3.9/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1640811803361/work/torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n"
     ]
    }
   ],
   "source": [
    "x,y = next(iter(data_loader))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = {'encoder_cat': tensor([], size=(16, 5, 0), dtype=torch.int64), 'encoder_cont': tensor([[[ 1.0000e+00, -1.1349e+00, -1.0375e+00,  8.5500e-01, -7.7623e-01,\n",
      "           1.0069e+00,  1.8451e-02],\n",
      "         [ 1.0000e+00, -9.3160e-01, -3.0177e-01, -4.6928e-01, -4.4722e-01,\n",
      "           1.2050e+00,  3.3144e-02],\n",
      "         [ 1.0000e+00,  1.6065e+00,  8.3318e-01, -6.4214e-01, -1.1026e-01,\n",
      "          -1.4283e+00,  2.1390e-02],\n",
      "         [ 1.0000e+00, -9.8043e-02, -7.4761e-02, -1.0222e+00, -1.5147e+00,\n",
      "           1.0295e+00,  3.7727e-02],\n",
      "         [ 1.0000e+00,  1.0356e+00,  1.1872e+00,  8.2175e-01,  1.2530e+00,\n",
      "           1.1223e+00,  5.2715e-03]],\n",
      "\n",
      "        [[ 1.0000e+00, -9.3160e-01, -3.0177e-01, -4.6928e-01, -4.4722e-01,\n",
      "           1.2050e+00,  3.3144e-02],\n",
      "         [ 1.0000e+00,  1.6065e+00,  8.3318e-01, -6.4214e-01, -1.1026e-01,\n",
      "          -1.4283e+00,  2.1390e-02],\n",
      "         [ 1.0000e+00, -9.8043e-02, -7.4761e-02, -1.0222e+00, -1.5147e+00,\n",
      "           1.0295e+00,  3.7727e-02],\n",
      "         [ 1.0000e+00,  1.0356e+00,  1.1872e+00,  8.2175e-01,  1.2530e+00,\n",
      "           1.1223e+00,  5.2715e-03],\n",
      "         [ 1.0000e+00,  7.1542e-01, -1.3198e+00,  7.6118e-01,  2.6301e-01,\n",
      "           5.0060e-01,  4.4627e-02]],\n",
      "\n",
      "        [[ 1.0000e+00,  1.6065e+00,  8.3318e-01, -6.4214e-01, -1.1026e-01,\n",
      "          -1.4283e+00,  2.1390e-02],\n",
      "         [ 1.0000e+00, -9.8043e-02, -7.4761e-02, -1.0222e+00, -1.5147e+00,\n",
      "           1.0295e+00,  3.7727e-02],\n",
      "         [ 1.0000e+00,  1.0356e+00,  1.1872e+00,  8.2175e-01,  1.2530e+00,\n",
      "           1.1223e+00,  5.2715e-03],\n",
      "         [ 1.0000e+00,  7.1542e-01, -1.3198e+00,  7.6118e-01,  2.6301e-01,\n",
      "           5.0060e-01,  4.4627e-02],\n",
      "         [ 1.0000e+00,  1.5232e+00,  1.7202e+00,  6.1780e-01, -1.6836e+00,\n",
      "          -1.0773e+00,  4.0529e-02]],\n",
      "\n",
      "        [[ 1.0000e+00, -9.8043e-02, -7.4761e-02, -1.0222e+00, -1.5147e+00,\n",
      "           1.0295e+00,  3.7727e-02],\n",
      "         [ 1.0000e+00,  1.0356e+00,  1.1872e+00,  8.2175e-01,  1.2530e+00,\n",
      "           1.1223e+00,  5.2715e-03],\n",
      "         [ 1.0000e+00,  7.1542e-01, -1.3198e+00,  7.6118e-01,  2.6301e-01,\n",
      "           5.0060e-01,  4.4627e-02],\n",
      "         [ 1.0000e+00,  1.5232e+00,  1.7202e+00,  6.1780e-01, -1.6836e+00,\n",
      "          -1.0773e+00,  4.0529e-02],\n",
      "         [ 1.0000e+00,  2.7391e-02,  1.4036e+00, -6.5653e-01,  9.5132e-01,\n",
      "           7.7652e-03,  1.2738e-03]],\n",
      "\n",
      "        [[ 1.0000e+00,  1.0356e+00,  1.1872e+00,  8.2175e-01,  1.2530e+00,\n",
      "           1.1223e+00,  5.2715e-03],\n",
      "         [ 1.0000e+00,  7.1542e-01, -1.3198e+00,  7.6118e-01,  2.6301e-01,\n",
      "           5.0060e-01,  4.4627e-02],\n",
      "         [ 1.0000e+00,  1.5232e+00,  1.7202e+00,  6.1780e-01, -1.6836e+00,\n",
      "          -1.0773e+00,  4.0529e-02],\n",
      "         [ 1.0000e+00,  2.7391e-02,  1.4036e+00, -6.5653e-01,  9.5132e-01,\n",
      "           7.7652e-03,  1.2738e-03],\n",
      "         [ 1.0000e+00, -5.6774e-01, -1.6286e+00, -3.9792e-01,  6.3433e-01,\n",
      "           3.7648e-01,  1.1710e-02]],\n",
      "\n",
      "        [[ 1.0000e+00,  7.1542e-01, -1.3198e+00,  7.6118e-01,  2.6301e-01,\n",
      "           5.0060e-01,  4.4627e-02],\n",
      "         [ 1.0000e+00,  1.5232e+00,  1.7202e+00,  6.1780e-01, -1.6836e+00,\n",
      "          -1.0773e+00,  4.0529e-02],\n",
      "         [ 1.0000e+00,  2.7391e-02,  1.4036e+00, -6.5653e-01,  9.5132e-01,\n",
      "           7.7652e-03,  1.2738e-03],\n",
      "         [ 1.0000e+00, -5.6774e-01, -1.6286e+00, -3.9792e-01,  6.3433e-01,\n",
      "           3.7648e-01,  1.1710e-02],\n",
      "         [ 1.0000e+00, -1.2889e+00, -8.2249e-01,  1.4839e+00, -1.6226e+00,\n",
      "          -8.9725e-01,  9.6437e-03]],\n",
      "\n",
      "        [[ 1.0000e+00,  1.5232e+00,  1.7202e+00,  6.1780e-01, -1.6836e+00,\n",
      "          -1.0773e+00,  4.0529e-02],\n",
      "         [ 1.0000e+00,  2.7391e-02,  1.4036e+00, -6.5653e-01,  9.5132e-01,\n",
      "           7.7652e-03,  1.2738e-03],\n",
      "         [ 1.0000e+00, -5.6774e-01, -1.6286e+00, -3.9792e-01,  6.3433e-01,\n",
      "           3.7648e-01,  1.1710e-02],\n",
      "         [ 1.0000e+00, -1.2889e+00, -8.2249e-01,  1.4839e+00, -1.6226e+00,\n",
      "          -8.9725e-01,  9.6437e-03],\n",
      "         [ 1.0000e+00, -1.1976e-01, -9.8207e-01,  9.4391e-01,  3.3746e-01,\n",
      "           8.3214e-01,  3.4957e-02]],\n",
      "\n",
      "        [[ 1.0000e+00,  2.7391e-02,  1.4036e+00, -6.5653e-01,  9.5132e-01,\n",
      "           7.7652e-03,  1.2738e-03],\n",
      "         [ 1.0000e+00, -5.6774e-01, -1.6286e+00, -3.9792e-01,  6.3433e-01,\n",
      "           3.7648e-01,  1.1710e-02],\n",
      "         [ 1.0000e+00, -1.2889e+00, -8.2249e-01,  1.4839e+00, -1.6226e+00,\n",
      "          -8.9725e-01,  9.6437e-03],\n",
      "         [ 1.0000e+00, -1.1976e-01, -9.8207e-01,  9.4391e-01,  3.3746e-01,\n",
      "           8.3214e-01,  3.4957e-02],\n",
      "         [ 1.0000e+00, -7.2218e-01,  9.7318e-01, -1.5302e+00,  1.0029e+00,\n",
      "          -3.8115e-01,  3.8987e-03]],\n",
      "\n",
      "        [[ 1.0000e+00, -5.6774e-01, -1.6286e+00, -3.9792e-01,  6.3433e-01,\n",
      "           3.7648e-01,  1.1710e-02],\n",
      "         [ 1.0000e+00, -1.2889e+00, -8.2249e-01,  1.4839e+00, -1.6226e+00,\n",
      "          -8.9725e-01,  9.6437e-03],\n",
      "         [ 1.0000e+00, -1.1976e-01, -9.8207e-01,  9.4391e-01,  3.3746e-01,\n",
      "           8.3214e-01,  3.4957e-02],\n",
      "         [ 1.0000e+00, -7.2218e-01,  9.7318e-01, -1.5302e+00,  1.0029e+00,\n",
      "          -3.8115e-01,  3.8987e-03],\n",
      "         [ 1.0000e+00,  1.6561e+00, -1.4258e+00, -1.5687e+00, -1.1726e+00,\n",
      "          -1.0431e+00,  3.8268e-02]],\n",
      "\n",
      "        [[ 1.0000e+00, -1.2889e+00, -8.2249e-01,  1.4839e+00, -1.6226e+00,\n",
      "          -8.9725e-01,  9.6437e-03],\n",
      "         [ 1.0000e+00, -1.1976e-01, -9.8207e-01,  9.4391e-01,  3.3746e-01,\n",
      "           8.3214e-01,  3.4957e-02],\n",
      "         [ 1.0000e+00, -7.2218e-01,  9.7318e-01, -1.5302e+00,  1.0029e+00,\n",
      "          -3.8115e-01,  3.8987e-03],\n",
      "         [ 1.0000e+00,  1.6561e+00, -1.4258e+00, -1.5687e+00, -1.1726e+00,\n",
      "          -1.0431e+00,  3.8268e-02],\n",
      "         [ 1.0000e+00, -1.0992e+00,  1.2289e+00,  4.6518e-01,  4.2372e-01,\n",
      "           5.0583e-01,  3.0716e-02]],\n",
      "\n",
      "        [[ 1.0000e+00, -1.1976e-01, -9.8207e-01,  9.4391e-01,  3.3746e-01,\n",
      "           8.3214e-01,  3.4957e-02],\n",
      "         [ 1.0000e+00, -7.2218e-01,  9.7318e-01, -1.5302e+00,  1.0029e+00,\n",
      "          -3.8115e-01,  3.8987e-03],\n",
      "         [ 1.0000e+00,  1.6561e+00, -1.4258e+00, -1.5687e+00, -1.1726e+00,\n",
      "          -1.0431e+00,  3.8268e-02],\n",
      "         [ 1.0000e+00, -1.0992e+00,  1.2289e+00,  4.6518e-01,  4.2372e-01,\n",
      "           5.0583e-01,  3.0716e-02],\n",
      "         [ 1.0000e+00,  1.6819e+00,  6.4565e-01,  8.1379e-01, -1.2654e+00,\n",
      "          -1.5223e+00,  1.7489e-02]],\n",
      "\n",
      "        [[ 1.0000e+00, -7.2218e-01,  9.7318e-01, -1.5302e+00,  1.0029e+00,\n",
      "          -3.8115e-01,  3.8987e-03],\n",
      "         [ 1.0000e+00,  1.6561e+00, -1.4258e+00, -1.5687e+00, -1.1726e+00,\n",
      "          -1.0431e+00,  3.8268e-02],\n",
      "         [ 1.0000e+00, -1.0992e+00,  1.2289e+00,  4.6518e-01,  4.2372e-01,\n",
      "           5.0583e-01,  3.0716e-02],\n",
      "         [ 1.0000e+00,  1.6819e+00,  6.4565e-01,  8.1379e-01, -1.2654e+00,\n",
      "          -1.5223e+00,  1.7489e-02],\n",
      "         [ 1.0000e+00, -1.5742e+00, -3.7606e-01,  1.1521e+00, -1.4046e+00,\n",
      "           7.7666e-01,  3.4460e-02]],\n",
      "\n",
      "        [[ 1.0000e+00,  1.6561e+00, -1.4258e+00, -1.5687e+00, -1.1726e+00,\n",
      "          -1.0431e+00,  3.8268e-02],\n",
      "         [ 1.0000e+00, -1.0992e+00,  1.2289e+00,  4.6518e-01,  4.2372e-01,\n",
      "           5.0583e-01,  3.0716e-02],\n",
      "         [ 1.0000e+00,  1.6819e+00,  6.4565e-01,  8.1379e-01, -1.2654e+00,\n",
      "          -1.5223e+00,  1.7489e-02],\n",
      "         [ 1.0000e+00, -1.5742e+00, -3.7606e-01,  1.1521e+00, -1.4046e+00,\n",
      "           7.7666e-01,  3.4460e-02],\n",
      "         [ 1.0000e+00,  2.5272e-01,  9.3479e-01, -5.7661e-01,  7.8147e-01,\n",
      "          -1.0624e-01,  2.7577e-02]],\n",
      "\n",
      "        [[ 1.0000e+00, -1.0992e+00,  1.2289e+00,  4.6518e-01,  4.2372e-01,\n",
      "           5.0583e-01,  3.0716e-02],\n",
      "         [ 1.0000e+00,  1.6819e+00,  6.4565e-01,  8.1379e-01, -1.2654e+00,\n",
      "          -1.5223e+00,  1.7489e-02],\n",
      "         [ 1.0000e+00, -1.5742e+00, -3.7606e-01,  1.1521e+00, -1.4046e+00,\n",
      "           7.7666e-01,  3.4460e-02],\n",
      "         [ 1.0000e+00,  2.5272e-01,  9.3479e-01, -5.7661e-01,  7.8147e-01,\n",
      "          -1.0624e-01,  2.7577e-02],\n",
      "         [ 1.0000e+00, -3.8295e-01,  4.0318e-01, -1.4592e+00,  6.0873e-01,\n",
      "          -3.8290e-01,  4.1103e-02]],\n",
      "\n",
      "        [[ 1.0000e+00,  1.6819e+00,  6.4565e-01,  8.1379e-01, -1.2654e+00,\n",
      "          -1.5223e+00,  1.7489e-02],\n",
      "         [ 1.0000e+00, -1.5742e+00, -3.7606e-01,  1.1521e+00, -1.4046e+00,\n",
      "           7.7666e-01,  3.4460e-02],\n",
      "         [ 1.0000e+00,  2.5272e-01,  9.3479e-01, -5.7661e-01,  7.8147e-01,\n",
      "          -1.0624e-01,  2.7577e-02],\n",
      "         [ 1.0000e+00, -3.8295e-01,  4.0318e-01, -1.4592e+00,  6.0873e-01,\n",
      "          -3.8290e-01,  4.1103e-02],\n",
      "         [ 1.0000e+00,  1.3774e+00,  1.4480e+00, -1.1021e+00,  1.5650e-01,\n",
      "          -9.3962e-01,  2.0780e-02]],\n",
      "\n",
      "        [[ 1.0000e+00, -1.5742e+00, -3.7606e-01,  1.1521e+00, -1.4046e+00,\n",
      "           7.7666e-01,  3.4460e-02],\n",
      "         [ 1.0000e+00,  2.5272e-01,  9.3479e-01, -5.7661e-01,  7.8147e-01,\n",
      "          -1.0624e-01,  2.7577e-02],\n",
      "         [ 1.0000e+00, -3.8295e-01,  4.0318e-01, -1.4592e+00,  6.0873e-01,\n",
      "          -3.8290e-01,  4.1103e-02],\n",
      "         [ 1.0000e+00,  1.3774e+00,  1.4480e+00, -1.1021e+00,  1.5650e-01,\n",
      "          -9.3962e-01,  2.0780e-02],\n",
      "         [ 1.0000e+00, -1.0906e+00, -1.2183e-01,  1.0359e-01,  1.1466e+00,\n",
      "          -1.5504e+00,  1.9083e-02]]]), 'encoder_target': tensor([[1000.4050, 1000.7326, 1000.4705, 1000.8348, 1000.1110],\n",
      "        [1000.7326, 1000.4705, 1000.8348, 1000.1110, 1000.9887],\n",
      "        [1000.4705, 1000.8348, 1000.1110, 1000.9887, 1000.8973],\n",
      "        [1000.8348, 1000.1110, 1000.9887, 1000.8973, 1000.0219],\n",
      "        [1000.1110, 1000.9887, 1000.8973, 1000.0219, 1000.2546],\n",
      "        [1000.9887, 1000.8973, 1000.0219, 1000.2546, 1000.2086],\n",
      "        [1000.8973, 1000.0219, 1000.2546, 1000.2086, 1000.7730],\n",
      "        [1000.0219, 1000.2546, 1000.2086, 1000.7730, 1000.0804],\n",
      "        [1000.2546, 1000.2086, 1000.7730, 1000.0804, 1000.8469],\n",
      "        [1000.2086, 1000.7730, 1000.0804, 1000.8469, 1000.6785],\n",
      "        [1000.7730, 1000.0804, 1000.8469, 1000.6785, 1000.3835],\n",
      "        [1000.0804, 1000.8469, 1000.6785, 1000.3835, 1000.7620],\n",
      "        [1000.8469, 1000.6785, 1000.3835, 1000.7620, 1000.6085],\n",
      "        [1000.6785, 1000.3835, 1000.7620, 1000.6085, 1000.9101],\n",
      "        [1000.3835, 1000.7620, 1000.6085, 1000.9101, 1000.4569],\n",
      "        [1000.7620, 1000.6085, 1000.9101, 1000.4569, 1000.4191]]), 'encoder_lengths': tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]), 'decoder_cat': tensor([], size=(16, 1, 0), dtype=torch.int64), 'decoder_cont': tensor([[[ 1.0000e+00,  7.1542e-01, -1.3198e+00,  7.6118e-01,  2.6301e-01,\n",
      "           5.0060e-01,  4.4627e-02]],\n",
      "\n",
      "        [[ 1.0000e+00,  1.5232e+00,  1.7202e+00,  6.1780e-01, -1.6836e+00,\n",
      "          -1.0773e+00,  4.0529e-02]],\n",
      "\n",
      "        [[ 1.0000e+00,  2.7391e-02,  1.4036e+00, -6.5653e-01,  9.5132e-01,\n",
      "           7.7652e-03,  1.2738e-03]],\n",
      "\n",
      "        [[ 1.0000e+00, -5.6774e-01, -1.6286e+00, -3.9792e-01,  6.3433e-01,\n",
      "           3.7648e-01,  1.1710e-02]],\n",
      "\n",
      "        [[ 1.0000e+00, -1.2889e+00, -8.2249e-01,  1.4839e+00, -1.6226e+00,\n",
      "          -8.9725e-01,  9.6437e-03]],\n",
      "\n",
      "        [[ 1.0000e+00, -1.1976e-01, -9.8207e-01,  9.4391e-01,  3.3746e-01,\n",
      "           8.3214e-01,  3.4957e-02]],\n",
      "\n",
      "        [[ 1.0000e+00, -7.2218e-01,  9.7318e-01, -1.5302e+00,  1.0029e+00,\n",
      "          -3.8115e-01,  3.8987e-03]],\n",
      "\n",
      "        [[ 1.0000e+00,  1.6561e+00, -1.4258e+00, -1.5687e+00, -1.1726e+00,\n",
      "          -1.0431e+00,  3.8268e-02]],\n",
      "\n",
      "        [[ 1.0000e+00, -1.0992e+00,  1.2289e+00,  4.6518e-01,  4.2372e-01,\n",
      "           5.0583e-01,  3.0716e-02]],\n",
      "\n",
      "        [[ 1.0000e+00,  1.6819e+00,  6.4565e-01,  8.1379e-01, -1.2654e+00,\n",
      "          -1.5223e+00,  1.7489e-02]],\n",
      "\n",
      "        [[ 1.0000e+00, -1.5742e+00, -3.7606e-01,  1.1521e+00, -1.4046e+00,\n",
      "           7.7666e-01,  3.4460e-02]],\n",
      "\n",
      "        [[ 1.0000e+00,  2.5272e-01,  9.3479e-01, -5.7661e-01,  7.8147e-01,\n",
      "          -1.0624e-01,  2.7577e-02]],\n",
      "\n",
      "        [[ 1.0000e+00, -3.8295e-01,  4.0318e-01, -1.4592e+00,  6.0873e-01,\n",
      "          -3.8290e-01,  4.1103e-02]],\n",
      "\n",
      "        [[ 1.0000e+00,  1.3774e+00,  1.4480e+00, -1.1021e+00,  1.5650e-01,\n",
      "          -9.3962e-01,  2.0780e-02]],\n",
      "\n",
      "        [[ 1.0000e+00, -1.0906e+00, -1.2183e-01,  1.0359e-01,  1.1466e+00,\n",
      "          -1.5504e+00,  1.9083e-02]],\n",
      "\n",
      "        [[ 1.0000e+00, -4.8576e-01, -2.5291e-01,  1.6335e+00, -6.7710e-01,\n",
      "           3.3863e-02,  3.6437e-02]]]), 'decoder_target': tensor([[1000.9887],\n",
      "        [1000.8973],\n",
      "        [1000.0219],\n",
      "        [1000.2546],\n",
      "        [1000.2086],\n",
      "        [1000.7730],\n",
      "        [1000.0804],\n",
      "        [1000.8469],\n",
      "        [1000.6785],\n",
      "        [1000.3835],\n",
      "        [1000.7620],\n",
      "        [1000.6085],\n",
      "        [1000.9101],\n",
      "        [1000.4569],\n",
      "        [1000.4191],\n",
      "        [1000.8060]]), 'decoder_lengths': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'decoder_time_idx': tensor([[ 6],\n",
      "        [ 7],\n",
      "        [ 8],\n",
      "        [ 9],\n",
      "        [10],\n",
      "        [11],\n",
      "        [12],\n",
      "        [13],\n",
      "        [14],\n",
      "        [15],\n",
      "        [16],\n",
      "        [17],\n",
      "        [18],\n",
      "        [19],\n",
      "        [20],\n",
      "        [21]]), 'groups': tensor([[0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0]]), 'target_scale': tensor([[999.9935,  22.3009],\n",
      "        [999.9935,  22.3009],\n",
      "        [999.9935,  22.3009],\n",
      "        [999.9935,  22.3009],\n",
      "        [999.9935,  22.3009],\n",
      "        [999.9935,  22.3009],\n",
      "        [999.9935,  22.3009],\n",
      "        [999.9935,  22.3009],\n",
      "        [999.9935,  22.3009],\n",
      "        [999.9935,  22.3009],\n",
      "        [999.9935,  22.3009],\n",
      "        [999.9935,  22.3009],\n",
      "        [999.9935,  22.3009],\n",
      "        [999.9935,  22.3009],\n",
      "        [999.9935,  22.3009],\n",
      "        [999.9935,  22.3009]])}\n",
      "\n",
      "y = (tensor([[1000.9887],\n",
      "        [1000.8973],\n",
      "        [1000.0219],\n",
      "        [1000.2546],\n",
      "        [1000.2086],\n",
      "        [1000.7730],\n",
      "        [1000.0804],\n",
      "        [1000.8469],\n",
      "        [1000.6785],\n",
      "        [1000.3835],\n",
      "        [1000.7620],\n",
      "        [1000.6085],\n",
      "        [1000.9101],\n",
      "        [1000.4569],\n",
      "        [1000.4191],\n",
      "        [1000.8060]]), None)\n",
      "\n",
      "sizes of x =\n",
      "\tencoder_cat = torch.Size([16, 5, 0])\n",
      "\tencoder_cont = torch.Size([16, 5, 7])\n",
      "\tencoder_target = torch.Size([16, 5])\n",
      "\tencoder_lengths = torch.Size([16])\n",
      "\tdecoder_cat = torch.Size([16, 1, 0])\n",
      "\tdecoder_cont = torch.Size([16, 1, 7])\n",
      "\tdecoder_target = torch.Size([16, 1])\n",
      "\tdecoder_lengths = torch.Size([16])\n",
      "\tdecoder_time_idx = torch.Size([16, 1])\n",
      "\tgroups = torch.Size([16, 1])\n",
      "\ttarget_scale = torch.Size([16, 2])\n"
     ]
    }
   ],
   "source": [
    "print(\"x =\", x)\n",
    "print(\"\\ny =\", y)\n",
    "print(\"\\nsizes of x =\")\n",
    "for key, value in x.items():\n",
    "    print(f\"\\t{key} = {value.size()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3>Transformer Architecture</h3>\n",
    "\n",
    "Note that the custom encoder contains:\n",
    "- a self attention layer\n",
    "- a feed forward layer (normal stuffnot ethat for the attention layer, the multihead attention needs the number of diemnsions to be divisible by the number of multi attention heads.\n",
    "\n",
    "<h3>Model 1 (used for language)</h3> (theirs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from torch.nn import TransformerEncoderLayer, TransformerEncoder\n",
    "from code_repo.transformer import PositionalEncoding\n",
    "import math\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "\n",
    "    def __init__(self, ntoken: int, d_model: int, nhead: int, d_hid: int,\n",
    "                 nlayers: int, dropout: float = 0.5):\n",
    "        super().__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.encoder = nn.Embedding(ntoken, d_model)\n",
    "        self.d_model = d_model\n",
    "        self.decoder = nn.Linear(d_model, ntoken)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self) -> None:\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src: torch.Tensor, src_mask: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            src: Tensor, shape [seq_len, batch_size]\n",
    "            src_mask: Tensor, shape [seq_len, seq_len]\n",
    "\n",
    "        Returns:\n",
    "            output Tensor of shape [seq_len, batch_size, ntoken]\n",
    "        \"\"\"\n",
    "        src = self.encoder(src) * math.sqrt(self.d_model)\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src, src_mask)\n",
    "        output = self.decoder(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "def generate_square_subsequent_mask(sz: int) -> torch.Tensor:\n",
    "    \"\"\"Generates an upper-triangular matrix of -inf, with zeros on diag.\"\"\"\n",
    "    return torch.triu(torch.ones(sz, sz) * float('-inf'), diagonal=1)\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [seq_len, batch_size, embedding_dim]\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3>Pytorch Adapter</h3>\n",
    "<p>Currently this contains a premade transformer model from the torch fellows</p>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "#note that this has to extract 'encoder_cont' from the input, then pass it to the saved transformer model\n",
    "\n",
    "class StockTransformerModel(BaseModel):\n",
    "\n",
    "    def __init__(self, d_model = 5, nhead = 5,\n",
    "                 num_encoder_layers = 6,\n",
    "                 num_decoder_layers = 6,\n",
    "                 dim_feedforward = 100,\n",
    "                 dropout = 0.1,\n",
    "                 activation = \"relu\"):\n",
    "\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(d_model, num_encoder_layers,\\\n",
    "                                  num_decoder_layers, dim_feedforward,\n",
    "                                  dropout)\n",
    "        self.d_model = d_model\n",
    "        self.nhead = nhead\n",
    "        self.num_encoder_layers = num_encoder_layers\n",
    "        self.num_decoder_layers = num_decoder_layers\n",
    "        self.dim_feedforward = dim_feedforward\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.network = nn.Transformer(d_model = self.d_model,\n",
    "                                      nhead = self.nhead,\n",
    "                                      num_encoder_layers = self.num_encoder_layers,\n",
    "                                      dim_feedforward= self.dim_feedforward,\n",
    "                                      dropout= self.dropout,\n",
    "                                      batch_first=True\n",
    "                                      #activation= self.activation\n",
    "                                      )\n",
    "\n",
    "        #how many features are we passing through\n",
    "\n",
    "        #custom_encoder = some class\n",
    "        #custom_decoder = some class\n",
    "\n",
    "        #feed forward already implemented\n",
    "    def forward(self, x):\n",
    "        #need to extract data from whats returned in batch\n",
    "        new_x = x[\"encoder_cont\"].squeeze(-1)\n",
    "        new_y = x['decoder_cont'].squeeze(-1)\n",
    "\n",
    "        pred = self.network(new_x, new_y)\n",
    "\n",
    "\n",
    "        prediction = self.transform_output(pred, target_scale=x[\"target_scale\"])\n",
    "        return self.to_netowrk_output(prediction=pred)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "the feature number of src and tgt must be equal to d_model",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Input \u001B[0;32mIn [15]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m model \u001B[38;5;241m=\u001B[39m StockTransformerModel()\n\u001B[0;32m----> 2\u001B[0m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/csc492_v2/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1098\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1099\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1103\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1104\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "Input \u001B[0;32mIn [14]\u001B[0m, in \u001B[0;36mStockTransformerModel.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     40\u001B[0m new_x \u001B[38;5;241m=\u001B[39m x[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mencoder_cont\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39msqueeze(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     41\u001B[0m new_y \u001B[38;5;241m=\u001B[39m x[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdecoder_cont\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39msqueeze(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m---> 43\u001B[0m pred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnetwork\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnew_x\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnew_y\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     46\u001B[0m prediction \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform_output(pred, target_scale\u001B[38;5;241m=\u001B[39mx[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtarget_scale\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mto_netowrk_output(prediction\u001B[38;5;241m=\u001B[39mpred)\n",
      "File \u001B[0;32m~/anaconda3/envs/csc492_v2/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1098\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1099\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1103\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1104\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/anaconda3/envs/csc492_v2/lib/python3.9/site-packages/torch/nn/modules/transformer.py:139\u001B[0m, in \u001B[0;36mTransformer.forward\u001B[0;34m(self, src, tgt, src_mask, tgt_mask, memory_mask, src_key_padding_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001B[0m\n\u001B[1;32m    136\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mthe batch number of src and tgt must be equal\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    138\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m src\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m2\u001B[39m) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39md_model \u001B[38;5;129;01mor\u001B[39;00m tgt\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m2\u001B[39m) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39md_model:\n\u001B[0;32m--> 139\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mthe feature number of src and tgt must be equal to d_model\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    141\u001B[0m memory \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencoder(src, mask\u001B[38;5;241m=\u001B[39msrc_mask, src_key_padding_mask\u001B[38;5;241m=\u001B[39msrc_key_padding_mask)\n\u001B[1;32m    142\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdecoder(tgt, memory, tgt_mask\u001B[38;5;241m=\u001B[39mtgt_mask, memory_mask\u001B[38;5;241m=\u001B[39mmemory_mask,\n\u001B[1;32m    143\u001B[0m                       tgt_key_padding_mask\u001B[38;5;241m=\u001B[39mtgt_key_padding_mask,\n\u001B[1;32m    144\u001B[0m                       memory_key_padding_mask\u001B[38;5;241m=\u001B[39mmemory_key_padding_mask)\n",
      "\u001B[0;31mRuntimeError\u001B[0m: the feature number of src and tgt must be equal to d_model"
     ]
    }
   ],
   "source": [
    "model = StockTransformerModel()\n",
    "model(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "{'encoder_cat': tensor([], size=(16, 5, 0), dtype=torch.int64),\n 'encoder_cont': tensor([[[ 1.0000e+00, -1.1349e+00, -1.0375e+00,  8.5500e-01, -7.7623e-01,\n            1.0069e+00,  1.8451e-02],\n          [ 1.0000e+00, -9.3160e-01, -3.0177e-01, -4.6928e-01, -4.4722e-01,\n            1.2050e+00,  3.3144e-02],\n          [ 1.0000e+00,  1.6065e+00,  8.3318e-01, -6.4214e-01, -1.1026e-01,\n           -1.4283e+00,  2.1390e-02],\n          [ 1.0000e+00, -9.8043e-02, -7.4761e-02, -1.0222e+00, -1.5147e+00,\n            1.0295e+00,  3.7727e-02],\n          [ 1.0000e+00,  1.0356e+00,  1.1872e+00,  8.2175e-01,  1.2530e+00,\n            1.1223e+00,  5.2715e-03]],\n \n         [[ 1.0000e+00, -9.3160e-01, -3.0177e-01, -4.6928e-01, -4.4722e-01,\n            1.2050e+00,  3.3144e-02],\n          [ 1.0000e+00,  1.6065e+00,  8.3318e-01, -6.4214e-01, -1.1026e-01,\n           -1.4283e+00,  2.1390e-02],\n          [ 1.0000e+00, -9.8043e-02, -7.4761e-02, -1.0222e+00, -1.5147e+00,\n            1.0295e+00,  3.7727e-02],\n          [ 1.0000e+00,  1.0356e+00,  1.1872e+00,  8.2175e-01,  1.2530e+00,\n            1.1223e+00,  5.2715e-03],\n          [ 1.0000e+00,  7.1542e-01, -1.3198e+00,  7.6118e-01,  2.6301e-01,\n            5.0060e-01,  4.4627e-02]],\n \n         [[ 1.0000e+00,  1.6065e+00,  8.3318e-01, -6.4214e-01, -1.1026e-01,\n           -1.4283e+00,  2.1390e-02],\n          [ 1.0000e+00, -9.8043e-02, -7.4761e-02, -1.0222e+00, -1.5147e+00,\n            1.0295e+00,  3.7727e-02],\n          [ 1.0000e+00,  1.0356e+00,  1.1872e+00,  8.2175e-01,  1.2530e+00,\n            1.1223e+00,  5.2715e-03],\n          [ 1.0000e+00,  7.1542e-01, -1.3198e+00,  7.6118e-01,  2.6301e-01,\n            5.0060e-01,  4.4627e-02],\n          [ 1.0000e+00,  1.5232e+00,  1.7202e+00,  6.1780e-01, -1.6836e+00,\n           -1.0773e+00,  4.0529e-02]],\n \n         [[ 1.0000e+00, -9.8043e-02, -7.4761e-02, -1.0222e+00, -1.5147e+00,\n            1.0295e+00,  3.7727e-02],\n          [ 1.0000e+00,  1.0356e+00,  1.1872e+00,  8.2175e-01,  1.2530e+00,\n            1.1223e+00,  5.2715e-03],\n          [ 1.0000e+00,  7.1542e-01, -1.3198e+00,  7.6118e-01,  2.6301e-01,\n            5.0060e-01,  4.4627e-02],\n          [ 1.0000e+00,  1.5232e+00,  1.7202e+00,  6.1780e-01, -1.6836e+00,\n           -1.0773e+00,  4.0529e-02],\n          [ 1.0000e+00,  2.7391e-02,  1.4036e+00, -6.5653e-01,  9.5132e-01,\n            7.7652e-03,  1.2738e-03]],\n \n         [[ 1.0000e+00,  1.0356e+00,  1.1872e+00,  8.2175e-01,  1.2530e+00,\n            1.1223e+00,  5.2715e-03],\n          [ 1.0000e+00,  7.1542e-01, -1.3198e+00,  7.6118e-01,  2.6301e-01,\n            5.0060e-01,  4.4627e-02],\n          [ 1.0000e+00,  1.5232e+00,  1.7202e+00,  6.1780e-01, -1.6836e+00,\n           -1.0773e+00,  4.0529e-02],\n          [ 1.0000e+00,  2.7391e-02,  1.4036e+00, -6.5653e-01,  9.5132e-01,\n            7.7652e-03,  1.2738e-03],\n          [ 1.0000e+00, -5.6774e-01, -1.6286e+00, -3.9792e-01,  6.3433e-01,\n            3.7648e-01,  1.1710e-02]],\n \n         [[ 1.0000e+00,  7.1542e-01, -1.3198e+00,  7.6118e-01,  2.6301e-01,\n            5.0060e-01,  4.4627e-02],\n          [ 1.0000e+00,  1.5232e+00,  1.7202e+00,  6.1780e-01, -1.6836e+00,\n           -1.0773e+00,  4.0529e-02],\n          [ 1.0000e+00,  2.7391e-02,  1.4036e+00, -6.5653e-01,  9.5132e-01,\n            7.7652e-03,  1.2738e-03],\n          [ 1.0000e+00, -5.6774e-01, -1.6286e+00, -3.9792e-01,  6.3433e-01,\n            3.7648e-01,  1.1710e-02],\n          [ 1.0000e+00, -1.2889e+00, -8.2249e-01,  1.4839e+00, -1.6226e+00,\n           -8.9725e-01,  9.6437e-03]],\n \n         [[ 1.0000e+00,  1.5232e+00,  1.7202e+00,  6.1780e-01, -1.6836e+00,\n           -1.0773e+00,  4.0529e-02],\n          [ 1.0000e+00,  2.7391e-02,  1.4036e+00, -6.5653e-01,  9.5132e-01,\n            7.7652e-03,  1.2738e-03],\n          [ 1.0000e+00, -5.6774e-01, -1.6286e+00, -3.9792e-01,  6.3433e-01,\n            3.7648e-01,  1.1710e-02],\n          [ 1.0000e+00, -1.2889e+00, -8.2249e-01,  1.4839e+00, -1.6226e+00,\n           -8.9725e-01,  9.6437e-03],\n          [ 1.0000e+00, -1.1976e-01, -9.8207e-01,  9.4391e-01,  3.3746e-01,\n            8.3214e-01,  3.4957e-02]],\n \n         [[ 1.0000e+00,  2.7391e-02,  1.4036e+00, -6.5653e-01,  9.5132e-01,\n            7.7652e-03,  1.2738e-03],\n          [ 1.0000e+00, -5.6774e-01, -1.6286e+00, -3.9792e-01,  6.3433e-01,\n            3.7648e-01,  1.1710e-02],\n          [ 1.0000e+00, -1.2889e+00, -8.2249e-01,  1.4839e+00, -1.6226e+00,\n           -8.9725e-01,  9.6437e-03],\n          [ 1.0000e+00, -1.1976e-01, -9.8207e-01,  9.4391e-01,  3.3746e-01,\n            8.3214e-01,  3.4957e-02],\n          [ 1.0000e+00, -7.2218e-01,  9.7318e-01, -1.5302e+00,  1.0029e+00,\n           -3.8115e-01,  3.8987e-03]],\n \n         [[ 1.0000e+00, -5.6774e-01, -1.6286e+00, -3.9792e-01,  6.3433e-01,\n            3.7648e-01,  1.1710e-02],\n          [ 1.0000e+00, -1.2889e+00, -8.2249e-01,  1.4839e+00, -1.6226e+00,\n           -8.9725e-01,  9.6437e-03],\n          [ 1.0000e+00, -1.1976e-01, -9.8207e-01,  9.4391e-01,  3.3746e-01,\n            8.3214e-01,  3.4957e-02],\n          [ 1.0000e+00, -7.2218e-01,  9.7318e-01, -1.5302e+00,  1.0029e+00,\n           -3.8115e-01,  3.8987e-03],\n          [ 1.0000e+00,  1.6561e+00, -1.4258e+00, -1.5687e+00, -1.1726e+00,\n           -1.0431e+00,  3.8268e-02]],\n \n         [[ 1.0000e+00, -1.2889e+00, -8.2249e-01,  1.4839e+00, -1.6226e+00,\n           -8.9725e-01,  9.6437e-03],\n          [ 1.0000e+00, -1.1976e-01, -9.8207e-01,  9.4391e-01,  3.3746e-01,\n            8.3214e-01,  3.4957e-02],\n          [ 1.0000e+00, -7.2218e-01,  9.7318e-01, -1.5302e+00,  1.0029e+00,\n           -3.8115e-01,  3.8987e-03],\n          [ 1.0000e+00,  1.6561e+00, -1.4258e+00, -1.5687e+00, -1.1726e+00,\n           -1.0431e+00,  3.8268e-02],\n          [ 1.0000e+00, -1.0992e+00,  1.2289e+00,  4.6518e-01,  4.2372e-01,\n            5.0583e-01,  3.0716e-02]],\n \n         [[ 1.0000e+00, -1.1976e-01, -9.8207e-01,  9.4391e-01,  3.3746e-01,\n            8.3214e-01,  3.4957e-02],\n          [ 1.0000e+00, -7.2218e-01,  9.7318e-01, -1.5302e+00,  1.0029e+00,\n           -3.8115e-01,  3.8987e-03],\n          [ 1.0000e+00,  1.6561e+00, -1.4258e+00, -1.5687e+00, -1.1726e+00,\n           -1.0431e+00,  3.8268e-02],\n          [ 1.0000e+00, -1.0992e+00,  1.2289e+00,  4.6518e-01,  4.2372e-01,\n            5.0583e-01,  3.0716e-02],\n          [ 1.0000e+00,  1.6819e+00,  6.4565e-01,  8.1379e-01, -1.2654e+00,\n           -1.5223e+00,  1.7489e-02]],\n \n         [[ 1.0000e+00, -7.2218e-01,  9.7318e-01, -1.5302e+00,  1.0029e+00,\n           -3.8115e-01,  3.8987e-03],\n          [ 1.0000e+00,  1.6561e+00, -1.4258e+00, -1.5687e+00, -1.1726e+00,\n           -1.0431e+00,  3.8268e-02],\n          [ 1.0000e+00, -1.0992e+00,  1.2289e+00,  4.6518e-01,  4.2372e-01,\n            5.0583e-01,  3.0716e-02],\n          [ 1.0000e+00,  1.6819e+00,  6.4565e-01,  8.1379e-01, -1.2654e+00,\n           -1.5223e+00,  1.7489e-02],\n          [ 1.0000e+00, -1.5742e+00, -3.7606e-01,  1.1521e+00, -1.4046e+00,\n            7.7666e-01,  3.4460e-02]],\n \n         [[ 1.0000e+00,  1.6561e+00, -1.4258e+00, -1.5687e+00, -1.1726e+00,\n           -1.0431e+00,  3.8268e-02],\n          [ 1.0000e+00, -1.0992e+00,  1.2289e+00,  4.6518e-01,  4.2372e-01,\n            5.0583e-01,  3.0716e-02],\n          [ 1.0000e+00,  1.6819e+00,  6.4565e-01,  8.1379e-01, -1.2654e+00,\n           -1.5223e+00,  1.7489e-02],\n          [ 1.0000e+00, -1.5742e+00, -3.7606e-01,  1.1521e+00, -1.4046e+00,\n            7.7666e-01,  3.4460e-02],\n          [ 1.0000e+00,  2.5272e-01,  9.3479e-01, -5.7661e-01,  7.8147e-01,\n           -1.0624e-01,  2.7577e-02]],\n \n         [[ 1.0000e+00, -1.0992e+00,  1.2289e+00,  4.6518e-01,  4.2372e-01,\n            5.0583e-01,  3.0716e-02],\n          [ 1.0000e+00,  1.6819e+00,  6.4565e-01,  8.1379e-01, -1.2654e+00,\n           -1.5223e+00,  1.7489e-02],\n          [ 1.0000e+00, -1.5742e+00, -3.7606e-01,  1.1521e+00, -1.4046e+00,\n            7.7666e-01,  3.4460e-02],\n          [ 1.0000e+00,  2.5272e-01,  9.3479e-01, -5.7661e-01,  7.8147e-01,\n           -1.0624e-01,  2.7577e-02],\n          [ 1.0000e+00, -3.8295e-01,  4.0318e-01, -1.4592e+00,  6.0873e-01,\n           -3.8290e-01,  4.1103e-02]],\n \n         [[ 1.0000e+00,  1.6819e+00,  6.4565e-01,  8.1379e-01, -1.2654e+00,\n           -1.5223e+00,  1.7489e-02],\n          [ 1.0000e+00, -1.5742e+00, -3.7606e-01,  1.1521e+00, -1.4046e+00,\n            7.7666e-01,  3.4460e-02],\n          [ 1.0000e+00,  2.5272e-01,  9.3479e-01, -5.7661e-01,  7.8147e-01,\n           -1.0624e-01,  2.7577e-02],\n          [ 1.0000e+00, -3.8295e-01,  4.0318e-01, -1.4592e+00,  6.0873e-01,\n           -3.8290e-01,  4.1103e-02],\n          [ 1.0000e+00,  1.3774e+00,  1.4480e+00, -1.1021e+00,  1.5650e-01,\n           -9.3962e-01,  2.0780e-02]],\n \n         [[ 1.0000e+00, -1.5742e+00, -3.7606e-01,  1.1521e+00, -1.4046e+00,\n            7.7666e-01,  3.4460e-02],\n          [ 1.0000e+00,  2.5272e-01,  9.3479e-01, -5.7661e-01,  7.8147e-01,\n           -1.0624e-01,  2.7577e-02],\n          [ 1.0000e+00, -3.8295e-01,  4.0318e-01, -1.4592e+00,  6.0873e-01,\n           -3.8290e-01,  4.1103e-02],\n          [ 1.0000e+00,  1.3774e+00,  1.4480e+00, -1.1021e+00,  1.5650e-01,\n           -9.3962e-01,  2.0780e-02],\n          [ 1.0000e+00, -1.0906e+00, -1.2183e-01,  1.0359e-01,  1.1466e+00,\n           -1.5504e+00,  1.9083e-02]]]),\n 'encoder_target': tensor([[1000.4050, 1000.7326, 1000.4705, 1000.8348, 1000.1110],\n         [1000.7326, 1000.4705, 1000.8348, 1000.1110, 1000.9887],\n         [1000.4705, 1000.8348, 1000.1110, 1000.9887, 1000.8973],\n         [1000.8348, 1000.1110, 1000.9887, 1000.8973, 1000.0219],\n         [1000.1110, 1000.9887, 1000.8973, 1000.0219, 1000.2546],\n         [1000.9887, 1000.8973, 1000.0219, 1000.2546, 1000.2086],\n         [1000.8973, 1000.0219, 1000.2546, 1000.2086, 1000.7730],\n         [1000.0219, 1000.2546, 1000.2086, 1000.7730, 1000.0804],\n         [1000.2546, 1000.2086, 1000.7730, 1000.0804, 1000.8469],\n         [1000.2086, 1000.7730, 1000.0804, 1000.8469, 1000.6785],\n         [1000.7730, 1000.0804, 1000.8469, 1000.6785, 1000.3835],\n         [1000.0804, 1000.8469, 1000.6785, 1000.3835, 1000.7620],\n         [1000.8469, 1000.6785, 1000.3835, 1000.7620, 1000.6085],\n         [1000.6785, 1000.3835, 1000.7620, 1000.6085, 1000.9101],\n         [1000.3835, 1000.7620, 1000.6085, 1000.9101, 1000.4569],\n         [1000.7620, 1000.6085, 1000.9101, 1000.4569, 1000.4191]]),\n 'encoder_lengths': tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]),\n 'decoder_cat': tensor([], size=(16, 1, 0), dtype=torch.int64),\n 'decoder_cont': tensor([[[ 1.0000e+00,  7.1542e-01, -1.3198e+00,  7.6118e-01,  2.6301e-01,\n            5.0060e-01,  4.4627e-02]],\n \n         [[ 1.0000e+00,  1.5232e+00,  1.7202e+00,  6.1780e-01, -1.6836e+00,\n           -1.0773e+00,  4.0529e-02]],\n \n         [[ 1.0000e+00,  2.7391e-02,  1.4036e+00, -6.5653e-01,  9.5132e-01,\n            7.7652e-03,  1.2738e-03]],\n \n         [[ 1.0000e+00, -5.6774e-01, -1.6286e+00, -3.9792e-01,  6.3433e-01,\n            3.7648e-01,  1.1710e-02]],\n \n         [[ 1.0000e+00, -1.2889e+00, -8.2249e-01,  1.4839e+00, -1.6226e+00,\n           -8.9725e-01,  9.6437e-03]],\n \n         [[ 1.0000e+00, -1.1976e-01, -9.8207e-01,  9.4391e-01,  3.3746e-01,\n            8.3214e-01,  3.4957e-02]],\n \n         [[ 1.0000e+00, -7.2218e-01,  9.7318e-01, -1.5302e+00,  1.0029e+00,\n           -3.8115e-01,  3.8987e-03]],\n \n         [[ 1.0000e+00,  1.6561e+00, -1.4258e+00, -1.5687e+00, -1.1726e+00,\n           -1.0431e+00,  3.8268e-02]],\n \n         [[ 1.0000e+00, -1.0992e+00,  1.2289e+00,  4.6518e-01,  4.2372e-01,\n            5.0583e-01,  3.0716e-02]],\n \n         [[ 1.0000e+00,  1.6819e+00,  6.4565e-01,  8.1379e-01, -1.2654e+00,\n           -1.5223e+00,  1.7489e-02]],\n \n         [[ 1.0000e+00, -1.5742e+00, -3.7606e-01,  1.1521e+00, -1.4046e+00,\n            7.7666e-01,  3.4460e-02]],\n \n         [[ 1.0000e+00,  2.5272e-01,  9.3479e-01, -5.7661e-01,  7.8147e-01,\n           -1.0624e-01,  2.7577e-02]],\n \n         [[ 1.0000e+00, -3.8295e-01,  4.0318e-01, -1.4592e+00,  6.0873e-01,\n           -3.8290e-01,  4.1103e-02]],\n \n         [[ 1.0000e+00,  1.3774e+00,  1.4480e+00, -1.1021e+00,  1.5650e-01,\n           -9.3962e-01,  2.0780e-02]],\n \n         [[ 1.0000e+00, -1.0906e+00, -1.2183e-01,  1.0359e-01,  1.1466e+00,\n           -1.5504e+00,  1.9083e-02]],\n \n         [[ 1.0000e+00, -4.8576e-01, -2.5291e-01,  1.6335e+00, -6.7710e-01,\n            3.3863e-02,  3.6437e-02]]]),\n 'decoder_target': tensor([[1000.9887],\n         [1000.8973],\n         [1000.0219],\n         [1000.2546],\n         [1000.2086],\n         [1000.7730],\n         [1000.0804],\n         [1000.8469],\n         [1000.6785],\n         [1000.3835],\n         [1000.7620],\n         [1000.6085],\n         [1000.9101],\n         [1000.4569],\n         [1000.4191],\n         [1000.8060]]),\n 'decoder_lengths': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n 'decoder_time_idx': tensor([[ 6],\n         [ 7],\n         [ 8],\n         [ 9],\n         [10],\n         [11],\n         [12],\n         [13],\n         [14],\n         [15],\n         [16],\n         [17],\n         [18],\n         [19],\n         [20],\n         [21]]),\n 'groups': tensor([[0],\n         [0],\n         [0],\n         [0],\n         [0],\n         [0],\n         [0],\n         [0],\n         [0],\n         [0],\n         [0],\n         [0],\n         [0],\n         [0],\n         [0],\n         [0]]),\n 'target_scale': tensor([[999.9935,  22.3009],\n         [999.9935,  22.3009],\n         [999.9935,  22.3009],\n         [999.9935,  22.3009],\n         [999.9935,  22.3009],\n         [999.9935,  22.3009],\n         [999.9935,  22.3009],\n         [999.9935,  22.3009],\n         [999.9935,  22.3009],\n         [999.9935,  22.3009],\n         [999.9935,  22.3009],\n         [999.9935,  22.3009],\n         [999.9935,  22.3009],\n         [999.9935,  22.3009],\n         [999.9935,  22.3009],\n         [999.9935,  22.3009]])}"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([16, 5, 7, 16, 1])"
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['encoder_cont'].size() + y[0].size()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'yx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [107]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43myx\u001B[49m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mencoder_cont\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39msize()\n",
      "\u001B[0;31mNameError\u001B[0m: name 'yx' is not defined"
     ]
    }
   ],
   "source": [
    "x['encoder_cont'].size()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#train model\n",
    "def train(model, data, batch_size=32,  learning_rate=0.1, momentum=0.9, total_epochs=10, weight_decay=0):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer= optim.Adam(model.parameters(), learning_rate=learning_rate, weight_decay=weight_decay)\n",
    "    total_loss = 0\n",
    "    losses = []\n",
    "    iterations = []\n",
    "    training_accuract = []\n",
    "    validation_accuract = []\n",
    "\n",
    "    num_iterations = 0\n",
    "    for epoch in range(0, total_epochs):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "data": {
      "text/plain": "<generator object Module.parameters at 0x7f96c84cfc80>"
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = StockTransformer()\n",
    "model.parameters()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "src = torch.rand((10, 32, 6))\n",
    "tgt = torch.rand((20,32,6))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "out = model(src, tgt)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.rand((1,2,3))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[ 1.8609e+00,  3.5001e-01,  5.2951e-01,  ..., -5.6568e-01,\n          -3.1149e-01, -8.8702e-01],\n         [ 1.3641e+00,  3.6736e-02,  6.4878e-01,  ...,  4.2819e-01,\n          -7.7870e-01,  5.3546e-01],\n         [ 1.5085e+00,  6.7698e-01,  5.3151e-01,  ...,  4.6038e-01,\n           2.2322e-01, -1.2730e+00],\n         ...,\n         [ 1.8146e+00,  7.0981e-01,  4.2588e-01,  ...,  9.0969e-01,\n           4.8604e-02,  1.7219e-01],\n         [ 1.8847e+00,  6.4794e-02,  1.6133e-01,  ...,  1.7033e-01,\n          -6.5030e-01,  1.1771e+00],\n         [ 1.1817e+00,  6.8779e-01,  5.2459e-01,  ..., -3.5132e-01,\n          -3.7258e-01, -5.6009e-02]],\n\n        [[ 1.0215e+00,  7.4425e-01,  1.1591e+00,  ...,  2.7391e-01,\n          -2.9277e-01, -1.4802e-01],\n         [ 1.9489e+00,  1.6937e-01,  2.9322e-01,  ...,  6.9300e-01,\n          -1.0268e+00,  3.5865e-01],\n         [ 1.4858e+00,  6.8375e-01,  1.0703e+00,  ...,  7.4776e-01,\n           2.1364e-01,  4.6723e-02],\n         ...,\n         [ 1.9812e+00,  7.7249e-01,  1.1114e+00,  ...,  5.7714e-01,\n          -4.7355e-01,  1.9327e-01],\n         [ 2.0568e+00,  8.3835e-01,  7.9678e-01,  ...,  2.3893e-02,\n          -5.6904e-01,  5.2341e-01],\n         [ 1.2154e+00,  1.3414e+00,  1.0384e+00,  ..., -4.8584e-01,\n           1.6820e-01,  8.4261e-01]],\n\n        [[ 1.4005e+00, -3.9579e-03,  2.6295e-01,  ...,  2.6633e-01,\n          -8.8358e-01,  2.9011e-01],\n         [ 1.5764e+00,  2.6680e-01,  7.0202e-01,  ...,  7.1652e-01,\n          -7.5740e-01,  1.5319e-01],\n         [ 9.2704e-01,  3.3642e-01,  7.9277e-01,  ...,  5.9988e-01,\n          -3.7554e-01, -2.7791e-01],\n         ...,\n         [ 1.3096e+00,  7.1499e-01,  1.1997e+00,  ..., -3.4324e-01,\n          -2.3558e-01, -1.1478e-01],\n         [ 1.6793e+00,  5.9849e-01,  9.4259e-01,  ...,  3.0393e-02,\n          -7.1690e-01, -2.8095e-01],\n         [ 1.8460e+00,  8.6415e-01,  1.0320e+00,  ..., -2.6610e-01,\n          -4.8128e-01,  1.4793e-01]],\n\n        ...,\n\n        [[ 1.6270e+00,  5.1395e-01,  1.5575e+00,  ...,  4.4120e-01,\n           8.6302e-01,  2.7452e-01],\n         [ 1.2132e+00, -5.2067e-02,  6.1256e-01,  ...,  2.4633e-01,\n          -4.6300e-01,  5.4387e-02],\n         [ 1.5218e+00,  2.3298e-01,  1.1459e+00,  ..., -6.5787e-01,\n          -2.7270e-01, -6.9753e-01],\n         ...,\n         [ 2.1243e+00,  1.0449e+00,  1.1757e-01,  ...,  5.7469e-01,\n          -6.2031e-01,  6.1834e-01],\n         [ 1.9299e+00,  7.7909e-01,  1.6217e-01,  ...,  4.4374e-01,\n          -5.3825e-01,  3.7104e-01],\n         [ 1.7415e+00,  1.0361e+00,  5.6567e-01,  ..., -1.5856e-01,\n          -2.6418e-01,  4.7155e-01]],\n\n        [[ 8.2413e-01, -1.4846e-01,  2.9891e-01,  ...,  2.3019e-01,\n           2.7850e-04, -1.0360e-01],\n         [ 1.3581e+00,  2.4826e-01,  2.9452e-01,  ...,  8.4746e-01,\n          -5.0659e-01,  1.1244e+00],\n         [ 1.1608e+00,  9.2114e-01,  9.6576e-01,  ..., -2.1513e-01,\n          -1.1932e+00, -2.6927e-01],\n         ...,\n         [ 7.6091e-01,  4.5270e-01,  4.6338e-01,  ...,  3.5564e-01,\n          -1.0805e+00, -1.1355e+00],\n         [ 1.2467e+00,  1.2111e+00,  1.0467e+00,  ...,  1.3540e-01,\n          -2.1274e-01, -7.5047e-01],\n         [ 6.0060e-01,  9.8755e-01,  7.9962e-01,  ..., -1.2321e-02,\n           2.5219e-01,  1.6050e-01]],\n\n        [[ 1.7934e+00,  7.5683e-01,  4.1987e-01,  ...,  3.7590e-02,\n          -1.4422e-01,  1.1782e-01],\n         [ 2.5753e+00,  3.7607e-01,  8.3770e-01,  ...,  4.5608e-01,\n          -5.3591e-01, -2.3224e-01],\n         [ 1.8376e+00,  3.0043e-01,  1.4269e+00,  ...,  5.1100e-01,\n          -4.1165e-01, -1.5803e-01],\n         ...,\n         [ 1.7462e+00,  7.0657e-01,  6.4432e-01,  ...,  1.2101e+00,\n          -1.7989e-01, -5.2918e-01],\n         [ 2.0691e+00,  5.2253e-01,  1.2977e+00,  ..., -1.9132e-01,\n          -3.9879e-01, -2.6848e-02],\n         [ 1.0723e+00,  7.7057e-01,  6.4880e-01,  ..., -4.1994e-01,\n          -3.8130e-01,  2.6043e-01]]], grad_fn=<NativeLayerNormBackward0>)"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "from pytorch_forecasting.data.examples import generate_ar_data\n",
    "\n",
    "timesteps = 1000\n",
    "\n",
    "data = generate_ar_data(seasonality=10.0, timesteps=timesteps, n_series=100, seed=42)\n",
    "data[\"static\"] = 2\n",
    "data[\"date\"] = pd.Timestamp(\"2020-01-01\") + pd.to_timedelta(data.time_idx, \"D\")\n",
    "\n",
    "data.series = data.series.astype(str).astype(\"category\")\n",
    "\n",
    "max_encoder_length = 30\n",
    "max_prediction_length = 15\n",
    "\n",
    "cutoff = timesteps * 0.70\n",
    "train_data = data[data[\"time_idx\"] <= cutoff]\n",
    "test_data = data[data[\"time_idx\"] > cutoff]\n",
    "\n",
    "training = TimeSeriesDataSet(\n",
    "    train_data,\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"value\",\n",
    "#      categorical_encoders={\"series\": NaNLabelEncoder().fit(train_data.series)},\n",
    "    group_ids=[\"series\"],\n",
    "    time_varying_unknown_reals=[\"value\"],\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    # allow_missing_timesteps=True,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "    def __init__(self, d_model: int, nhead: int, d_hid: int,\n",
    "                 nlayers: int, dropout: float = 0.5):\n",
    "        super().__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.embedding = nn.Linear(5, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout, batch_first=True)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.d_model = d_model\n",
    "        self.decoder = nn.Linear(d_model * 2, 1)\n",
    "\n",
    "        self.init_weights()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#sloan stuff"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(sz: int) -> Tensor:\n",
    "    \"\"\"Generates an upper-triangular matrix of -inf, with zeros on diag.\"\"\"\n",
    "    return torch.triu(torch.ones(sz, sz) * float('-inf'), diagonal=1)\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(1, max_len, d_model)\n",
    "        pe[0, :, 0::2] = torch.sin(position * div_term)\n",
    "        pe[0, :, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [batch_size, seq_len, embedding_dim]\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:,:x.size(1)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, d_model: int, nhead: int, d_hid: int,\n",
    "                 nlayers: int, dropout: float = 0.5):\n",
    "        super().__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.embedding = nn.Linear(5, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout, batch_first=True)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.d_model = d_model\n",
    "        self.decoder = nn.Linear(d_model * 2, 1)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self) -> None:\n",
    "        initrange = 0.1\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src: Tensor, src_mask: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            src: Tensor, shape [batch_size, seq_len]\n",
    "            src_mask: Tensor, shape [seq_len, seq_len]\n",
    "\n",
    "        Returns:\n",
    "            output Tensor of shape [batch_size, seq_len, ntoken]\n",
    "        \"\"\"\n",
    "        src = self.embedding(src)\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src, src_mask)\n",
    "        output = torch.concat([torch.max(output, dim=1)[0], torch.mean(output, dim=1)], dim=1)\n",
    "        output = self.decoder(output)\n",
    "        return output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "       value  group  time_idx\n0   0.104145      0         0\n1  -0.408156      0         1\n2  -0.027650      0         2\n3   0.468365      0         3\n4  -0.188278      0         4\n5  -0.173244      0         5\n6  -0.285444      0         6\n7  -0.124239      0         7\n8  -0.262205      0         8\n9   0.174174      0         9\n10 -0.324031      1         0\n11  0.304083      1         1\n12 -0.441632      1         2\n13  0.200891      1         3\n14 -0.128754      1         4\n15 -0.082647      1         5\n16 -0.429988      1         6\n17 -0.499547      1         7\n18  0.387851      1         8\n19 -0.204230      1         9\n20 -0.057724      2         0\n21  0.128085      2         1\n22  0.053239      2         2\n23  0.328398      2         3\n24 -0.325298      2         4\n25 -0.431351      2         5\n26  0.135290      2         6\n27 -0.137431      2         7\n28  0.182330      2         8\n29  0.394359      2         9",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>value</th>\n      <th>group</th>\n      <th>time_idx</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.104145</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.408156</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.027650</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.468365</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.188278</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>-0.173244</td>\n      <td>0</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>-0.285444</td>\n      <td>0</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>-0.124239</td>\n      <td>0</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>-0.262205</td>\n      <td>0</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.174174</td>\n      <td>0</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>-0.324031</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0.304083</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>-0.441632</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0.200891</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>-0.128754</td>\n      <td>1</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>-0.082647</td>\n      <td>1</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>-0.429988</td>\n      <td>1</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>-0.499547</td>\n      <td>1</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>0.387851</td>\n      <td>1</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>-0.204230</td>\n      <td>1</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>-0.057724</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>0.128085</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>0.053239</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>0.328398</td>\n      <td>2</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>-0.325298</td>\n      <td>2</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>-0.431351</td>\n      <td>2</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>0.135290</td>\n      <td>2</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>-0.137431</td>\n      <td>2</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>0.182330</td>\n      <td>2</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>0.394359</td>\n      <td>2</td>\n      <td>9</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.DataFrame(\n",
    "    dict(\n",
    "        value=np.random.rand(30) - 0.5,\n",
    "        group=np.repeat(np.arange(3), 10),\n",
    "        time_idx=np.tile(np.arange(10), 3),\n",
    "    )\n",
    ")\n",
    "test_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "# create the dataset from the pandas dataframe\n",
    "dataset = TimeSeriesDataSet(\n",
    "    test_data,\n",
    "    group_ids=[\"group\"],\n",
    "    target=\"value\",\n",
    "    time_idx=\"time_idx\",\n",
    "    min_encoder_length=5,\n",
    "    max_encoder_length=5,\n",
    "    min_prediction_length=2,\n",
    "    max_prediction_length=2,\n",
    "    time_varying_unknown_reals=[\"value\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = {'encoder_cat': tensor([], size=(4, 5, 0), dtype=torch.int64), 'encoder_cont': tensor([[[ 0.1013],\n",
      "         [ 1.8939],\n",
      "         [-0.4792],\n",
      "         [-0.4248],\n",
      "         [-0.8303]],\n",
      "\n",
      "        [[-1.3947],\n",
      "         [ 0.9272],\n",
      "         [-0.2640],\n",
      "         [-0.0974],\n",
      "         [-1.3527]],\n",
      "\n",
      "        [[-1.2738],\n",
      "         [ 0.1013],\n",
      "         [ 1.8939],\n",
      "         [-0.4792],\n",
      "         [-0.4248]],\n",
      "\n",
      "        [[ 0.3936],\n",
      "         [ 1.3880],\n",
      "         [-0.9743],\n",
      "         [-1.3576],\n",
      "         [ 0.6902]]]), 'encoder_target': tensor([[-0.0276,  0.4684, -0.1883, -0.1732, -0.2854],\n",
      "        [-0.4416,  0.2009, -0.1288, -0.0826, -0.4300],\n",
      "        [-0.4082, -0.0276,  0.4684, -0.1883, -0.1732],\n",
      "        [ 0.0532,  0.3284, -0.3253, -0.4314,  0.1353]]), 'encoder_lengths': tensor([5, 5, 5, 5]), 'decoder_cat': tensor([], size=(4, 2, 0), dtype=torch.int64), 'decoder_cont': tensor([[[-0.2477],\n",
      "         [-0.7463]],\n",
      "\n",
      "        [[-1.6040],\n",
      "         [ 1.6029]],\n",
      "\n",
      "        [[-0.8303],\n",
      "         [-0.2477]],\n",
      "\n",
      "        [[-0.2954],\n",
      "         [ 0.8602]]]), 'decoder_target': tensor([[-0.1242, -0.2622],\n",
      "        [-0.4995,  0.3879],\n",
      "        [-0.2854, -0.1242],\n",
      "        [-0.1374,  0.1823]]), 'decoder_lengths': tensor([2, 2, 2, 2]), 'decoder_time_idx': tensor([[7, 8],\n",
      "        [7, 8],\n",
      "        [6, 7],\n",
      "        [7, 8]]), 'groups': tensor([[0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [2]]), 'target_scale': tensor([[-0.0557,  0.2767],\n",
      "        [-0.0557,  0.2767],\n",
      "        [-0.0557,  0.2767],\n",
      "        [-0.0557,  0.2767]])}\n",
      "\n",
      "y = (tensor([[-0.1242, -0.2622],\n",
      "        [-0.4995,  0.3879],\n",
      "        [-0.2854, -0.1242],\n",
      "        [-0.1374,  0.1823]]), None)\n",
      "\n",
      "sizes of x =\n",
      "\tencoder_cat = torch.Size([4, 5, 0])\n",
      "\tencoder_cont = torch.Size([4, 5, 1])\n",
      "\tencoder_target = torch.Size([4, 5])\n",
      "\tencoder_lengths = torch.Size([4])\n",
      "\tdecoder_cat = torch.Size([4, 2, 0])\n",
      "\tdecoder_cont = torch.Size([4, 2, 1])\n",
      "\tdecoder_target = torch.Size([4, 2])\n",
      "\tdecoder_lengths = torch.Size([4])\n",
      "\tdecoder_time_idx = torch.Size([4, 2])\n",
      "\tgroups = torch.Size([4, 1])\n",
      "\ttarget_scale = torch.Size([4, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kagema/anaconda3/envs/csc492_v2/lib/python3.9/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1640811803361/work/torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n"
     ]
    }
   ],
   "source": [
    "dataloader = dataset.to_dataloader(batch_size=4)\n",
    "\n",
    "# and load the first batch\n",
    "x, y = next(iter(dataloader))\n",
    "print(\"x =\", x)\n",
    "print(\"\\ny =\", y)\n",
    "print(\"\\nsizes of x =\")\n",
    "for key, value in x.items():\n",
    "    print(f\"\\t{key} = {value.size()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Time2Vector(Layer):\n",
    "  def __init__(self, seq_len, **kwargs):\n",
    "    super(Time2Vector, self).__init__()\n",
    "    self.seq_len = seq_len\n",
    "\n",
    "  def build(self, input_shape):\n",
    "    self.weights_linear = self.add_weight(name='weight_linear',\n",
    "                                shape=(int(self.seq_len),),\n",
    "                                initializer='uniform',\n",
    "                                trainable=True)\n",
    "\n",
    "    self.bias_linear = self.add_weight(name='bias_linear',\n",
    "                                shape=(int(self.seq_len),),\n",
    "                                initializer='uniform',\n",
    "                                trainable=True)\n",
    "\n",
    "    self.weights_periodic = self.add_weight(name='weight_periodic',\n",
    "                                shape=(int(self.seq_len),),\n",
    "                                initializer='uniform',\n",
    "                                trainable=True)\n",
    "\n",
    "    self.bias_periodic = self.add_weight(name='bias_periodic',\n",
    "                                shape=(int(self.seq_len),),\n",
    "                                initializer='uniform',\n",
    "                                trainable=True)\n",
    "\n",
    "  def call(self, x):\n",
    "    x = tf.math.reduce_mean(x[:,:,:4], axis=-1) # Convert (batch, seq_len, 5) to (batch, seq_len)\n",
    "    time_linear = self.weights_linear * x + self.bias_linear\n",
    "    time_linear = tf.expand_dims(time_linear, axis=-1) # (batch, seq_len, 1)\n",
    "\n",
    "    time_periodic = tf.math.sin(tf.multiply(x, self.weights_periodic) + self.bias_periodic)\n",
    "    time_periodic = tf.expand_dims(time_periodic, axis=-1) # (batch, seq_len, 1)\n",
    "    return tf.concat([time_linear, time_periodic], axis=-1) # (batch, seq_len, 2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}