{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h2>Stock Market Transformer Model</h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot\n",
    "from pytorch_forecasting import TimeSeriesDataSet\n",
    "from pytorch_forecasting.data.encoders import TorchNormalizer\n",
    "import torch.nn as nn\n",
    "import torch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3>Data</h3>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'rand'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[0;32mIn [44]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      3\u001B[0m data\u001B[38;5;241m.\u001B[39mhead()\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m#create random data\u001B[39;00m\n\u001B[1;32m      6\u001B[0m random_timeseries \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(\n\u001B[1;32m      7\u001B[0m     \u001B[38;5;28mdict\u001B[39m(\n\u001B[1;32m      8\u001B[0m     date\u001B[38;5;241m=\u001B[39m[x \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m1000\u001B[39m)],\n\u001B[0;32m----> 9\u001B[0m     \u001B[38;5;28mopen\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrand\u001B[49m(\u001B[38;5;241m1000\u001B[39m) \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m0.2\u001B[39m,\n\u001B[1;32m     10\u001B[0m     close\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mrand(\u001B[38;5;241m1000\u001B[39m) \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1000\u001B[39m     \n\u001B[1;32m     11\u001B[0m     ))\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28mdict\u001B[39m\n",
      "File \u001B[0;32m~/anaconda3/envs/csc492_v2/lib/python3.9/site-packages/numpy/__init__.py:214\u001B[0m, in \u001B[0;36m__getattr__\u001B[0;34m(attr)\u001B[0m\n\u001B[1;32m    212\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m Tester\n\u001B[1;32m    213\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 214\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodule \u001B[39m\u001B[38;5;132;01m{!r}\u001B[39;00m\u001B[38;5;124m has no attribute \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    215\u001B[0m                          \u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{!r}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;18m__name__\u001B[39m, attr))\n",
      "\u001B[0;31mAttributeError\u001B[0m: module 'numpy' has no attribute 'rand'"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "data = yf.download(tickers=\"AAPL\", period='max', interval='1d', groupby='ticker', auto_adjust='True')\n",
    "data.head()\n",
    "\n",
    "#create random data\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "     date      open        close       high       low    volume       target\n0       1  0.292381  1000.811746  18.377700  2.486988  2.152189  1000.456786\n1       2  1.075209  1000.456786  18.152134  2.630768  2.505689  1000.974828\n2       3  1.107432  1000.974828  18.528306  2.929421  2.145361  1000.318113\n3       4  0.410290  1000.318113  18.563099  2.818635  2.960683  1000.661179\n4       5  0.513783  1000.661179  18.478306  2.102424  2.807739  1000.335845\n..    ...       ...          ...        ...       ...       ...          ...\n995   996  0.435977  1000.528506  18.788124  2.450938  2.984829  1000.433002\n996   997  0.334410  1000.433002  18.592034  2.501265  2.239090  1000.184201\n997   998  0.536333  1000.184201  18.264480  2.527732  2.991516  1000.660514\n998   999  0.802447  1000.660514  18.965601  2.907160  2.853034  1000.267608\n999  1000  0.572727  1000.267608  18.298097  2.623267  2.739759          NaN\n\n[1000 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>open</th>\n      <th>close</th>\n      <th>high</th>\n      <th>low</th>\n      <th>volume</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0.292381</td>\n      <td>1000.811746</td>\n      <td>18.377700</td>\n      <td>2.486988</td>\n      <td>2.152189</td>\n      <td>1000.456786</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1.075209</td>\n      <td>1000.456786</td>\n      <td>18.152134</td>\n      <td>2.630768</td>\n      <td>2.505689</td>\n      <td>1000.974828</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1.107432</td>\n      <td>1000.974828</td>\n      <td>18.528306</td>\n      <td>2.929421</td>\n      <td>2.145361</td>\n      <td>1000.318113</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0.410290</td>\n      <td>1000.318113</td>\n      <td>18.563099</td>\n      <td>2.818635</td>\n      <td>2.960683</td>\n      <td>1000.661179</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0.513783</td>\n      <td>1000.661179</td>\n      <td>18.478306</td>\n      <td>2.102424</td>\n      <td>2.807739</td>\n      <td>1000.335845</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>995</th>\n      <td>996</td>\n      <td>0.435977</td>\n      <td>1000.528506</td>\n      <td>18.788124</td>\n      <td>2.450938</td>\n      <td>2.984829</td>\n      <td>1000.433002</td>\n    </tr>\n    <tr>\n      <th>996</th>\n      <td>997</td>\n      <td>0.334410</td>\n      <td>1000.433002</td>\n      <td>18.592034</td>\n      <td>2.501265</td>\n      <td>2.239090</td>\n      <td>1000.184201</td>\n    </tr>\n    <tr>\n      <th>997</th>\n      <td>998</td>\n      <td>0.536333</td>\n      <td>1000.184201</td>\n      <td>18.264480</td>\n      <td>2.527732</td>\n      <td>2.991516</td>\n      <td>1000.660514</td>\n    </tr>\n    <tr>\n      <th>998</th>\n      <td>999</td>\n      <td>0.802447</td>\n      <td>1000.660514</td>\n      <td>18.965601</td>\n      <td>2.907160</td>\n      <td>2.853034</td>\n      <td>1000.267608</td>\n    </tr>\n    <tr>\n      <th>999</th>\n      <td>1000</td>\n      <td>0.572727</td>\n      <td>1000.267608</td>\n      <td>18.298097</td>\n      <td>2.623267</td>\n      <td>2.739759</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>1000 rows Ã— 7 columns</p>\n</div>"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_timeseries = pd.DataFrame(\n",
    "    dict(\n",
    "    date=[x for x in range(1,1001)],\n",
    "    open=np.random.rand(1000) + 0.2,\n",
    "    close=np.random.rand(1000) + 1000,\n",
    "        high=np.random.rand(1000) + 18,\n",
    "        low = np.random.rand(1000) + 2,\n",
    "        volume=np.random.rand(1000) + 2\n",
    "    ))\n",
    "random_timeseries[\"target\"] = random_timeseries.close.shift(-1)\n",
    "random_timeseries.fillna(3)\n",
    "random_timeseries"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kagema/anaconda3/envs/csc492_v2/lib/python3.9/site-packages/pytorch_forecasting/data/timeseries.py:1238: UserWarning: Min encoder length and/or min_prediction_idx and/or min prediction length and/or lags are too large for 1000 series/groups which therefore are not present in the dataset index. This means no predictions can be made for those series. First 10 removed groups: [{'__group_id__open': 0.20177707821027074, '__group_id__close': 1000.950979287919, '__group_id__high': 18.483054297444216, '__group_id__low': 2.0641541866888065, '__group_id__volume': 2.2564242560663903}, {'__group_id__open': 0.2032789141479468, '__group_id__close': 1000.8677495555643, '__group_id__high': 18.61443423317825, '__group_id__low': 2.9307022308733983, '__group_id__volume': 2.4734635792008732}, {'__group_id__open': 0.20436305172714458, '__group_id__close': 1000.6561191912484, '__group_id__high': 18.932801938271723, '__group_id__low': 2.088536510136771, '__group_id__volume': 2.6125118119636577}, {'__group_id__open': 0.20450768822267712, '__group_id__close': 1000.1102151038899, '__group_id__high': 18.163780898189337, '__group_id__low': 2.4220536057430664, '__group_id__volume': 2.8033825338881466}, {'__group_id__open': 0.2092910981738218, '__group_id__close': 1000.5766888503223, '__group_id__high': 18.276460388037822, '__group_id__low': 2.208947127795253, '__group_id__volume': 2.3420430224608246}, {'__group_id__open': 0.2093396142451403, '__group_id__close': 1000.1438629883456, '__group_id__high': 18.205046315709225, '__group_id__low': 2.601960648255419, '__group_id__volume': 2.875489623790501}, {'__group_id__open': 0.2101068333879122, '__group_id__close': 1000.2171688221521, '__group_id__high': 18.911387684938852, '__group_id__low': 2.6161164968682926, '__group_id__volume': 2.57193198395107}, {'__group_id__open': 0.2107441440630537, '__group_id__close': 1000.2528056373651, '__group_id__high': 18.126391413750696, '__group_id__low': 2.111844297656873, '__group_id__volume': 2.052131993220649}, {'__group_id__open': 0.21291789103818032, '__group_id__close': 1000.900257303278, '__group_id__high': 18.2052476896266, '__group_id__low': 2.112559143908432, '__group_id__volume': 2.979257827341883}, {'__group_id__open': 0.2150434742514164, '__group_id__close': 1000.0062762929857, '__group_id__high': 18.009960124913995, '__group_id__low': 2.4064503528494376, '__group_id__volume': 2.259433025326411}]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "filters should not remove entries all entries - check encoder/decoder lengths and lags",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[0;32mIn [57]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m#normalizer, add later\u001B[39;00m\n\u001B[1;32m      9\u001B[0m target_normalizer\u001B[38;5;241m=\u001B[39m TorchNormalizer()\n\u001B[0;32m---> 11\u001B[0m pytorch_random_dataset \u001B[38;5;241m=\u001B[39m \u001B[43mTimeSeriesDataSet\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrandom_timeseries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     12\u001B[0m \u001B[43m                                           \u001B[49m\u001B[43mgroup_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     13\u001B[0m \u001B[43m                                           \u001B[49m\u001B[43mtime_idx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtime_idx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     14\u001B[0m \u001B[43m                                           \u001B[49m\u001B[43mtarget\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     15\u001B[0m \u001B[43m                                           \u001B[49m\u001B[43mmax_prediction_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_prediction_length\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     16\u001B[0m \u001B[43m                                           \u001B[49m\u001B[43mtime_varying_unknown_reals\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtime_varying_unknown_reals\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     17\u001B[0m \u001B[43m                                           \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/csc492_v2/lib/python3.9/site-packages/pytorch_forecasting/data/timeseries.py:439\u001B[0m, in \u001B[0;36mTimeSeriesDataSet.__init__\u001B[0;34m(self, data, time_idx, target, group_ids, weight, max_encoder_length, min_encoder_length, min_prediction_idx, min_prediction_length, max_prediction_length, static_categoricals, static_reals, time_varying_known_categoricals, time_varying_known_reals, time_varying_unknown_categoricals, time_varying_unknown_reals, variable_groups, constant_fill_strategy, allow_missing_timesteps, lags, add_relative_time_idx, add_target_scales, add_encoder_length, target_normalizer, categorical_encoders, scalers, randomize_length, predict_mode)\u001B[0m\n\u001B[1;32m    436\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m target \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscalers, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTarget normalizer is separate and not in scalers.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    438\u001B[0m \u001B[38;5;66;03m# create index\u001B[39;00m\n\u001B[0;32m--> 439\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindex \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_construct_index\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpredict_mode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpredict_mode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    441\u001B[0m \u001B[38;5;66;03m# convert to torch tensor for high performance data loading later\u001B[39;00m\n\u001B[1;32m    442\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_data_to_tensors(data)\n",
      "File \u001B[0;32m~/anaconda3/envs/csc492_v2/lib/python3.9/site-packages/pytorch_forecasting/data/timeseries.py:1246\u001B[0m, in \u001B[0;36mTimeSeriesDataSet._construct_index\u001B[0;34m(self, data, predict_mode)\u001B[0m\n\u001B[1;32m   1237\u001B[0m         missing_groups[\u001B[38;5;28mid\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform_values(name, missing_groups[\u001B[38;5;28mid\u001B[39m], inverse\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, group_id\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m   1238\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m   1239\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMin encoder length and/or min_prediction_idx and/or min prediction length and/or lags are \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1240\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtoo large for \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1244\u001B[0m         \u001B[38;5;167;01mUserWarning\u001B[39;00m,\n\u001B[1;32m   1245\u001B[0m     )\n\u001B[0;32m-> 1246\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m (\n\u001B[1;32m   1247\u001B[0m     \u001B[38;5;28mlen\u001B[39m(df_index) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m   1248\u001B[0m ), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfilters should not remove entries all entries - check encoder/decoder lengths and lags\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1250\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m df_index\n",
      "\u001B[0;31mAssertionError\u001B[0m: filters should not remove entries all entries - check encoder/decoder lengths and lags"
     ]
    }
   ],
   "source": [
    "#what features constitute a single timeseries sample\n",
    "group_ids = ['open', 'close', 'high', 'low', 'volume']\n",
    "target='target'\n",
    "time_idx = 'date'\n",
    "\n",
    "max_prediction_length=1 #one day\n",
    "#list of continous variables that change over time and are not known in the future\n",
    "time_varying_unknown_reals = ['open', 'close', 'high', 'low', 'volume', 'target']\n",
    "#normalizer, add later\n",
    "target_normalizer= TorchNormalizer()\n",
    "\n",
    "pytorch_random_dataset = TimeSeriesDataSet(random_timeseries,\n",
    "                                           group_ids=group_ids,\n",
    "                                           time_idx=time_idx,\n",
    "                                           target=target,\n",
    "                                           max_prediction_length=max_prediction_length,\n",
    "                                           time_varying_unknown_reals=time_varying_unknown_reals,\n",
    "                                           max_prediction_length = max_prediction_length\n",
    "                                           )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3>Transformer Architecture</h3>\n",
    "\n",
    "Note that the custom encoder contains:\n",
    "- a self attention layer\n",
    "- a feed forward layer (normal stuffnot ethat for the attention layer, the multihead attention needs the number of diemnsions to be divisible by the number of multi attention heads."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "class StockTransformer(nn.Transformer):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            d_model = 6, #pytorch forces the number of dimensions to be divisible by number of md heads\n",
    "            nhead=3,\n",
    "            num_encoder_layers=8,\n",
    "            num_decoder_layers = 8,\n",
    "            dropout=0.1,\n",
    "            activation='relu') #not passing everything so we can keep it broken down here\n",
    "\n",
    "        #how many features are we passing through\n",
    "\n",
    "        #custom_encoder = some class\n",
    "        #custom_decoder = some class\n",
    "\n",
    "        #feed forward already implemented\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#train model\n",
    "def train(model, data, batch_size=32, optimizer=\"Adam\", learning_rate=0.1, momentum=0.9, num_epochs=10):\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "model = StockTransformer()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "src = torch.rand((10, 32, 6))\n",
    "tgt = torch.rand((20,32,6))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "out = model(src, tgt)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.rand((1,2,3))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[ 1.8609e+00,  3.5001e-01,  5.2951e-01,  ..., -5.6568e-01,\n          -3.1149e-01, -8.8702e-01],\n         [ 1.3641e+00,  3.6736e-02,  6.4878e-01,  ...,  4.2819e-01,\n          -7.7870e-01,  5.3546e-01],\n         [ 1.5085e+00,  6.7698e-01,  5.3151e-01,  ...,  4.6038e-01,\n           2.2322e-01, -1.2730e+00],\n         ...,\n         [ 1.8146e+00,  7.0981e-01,  4.2588e-01,  ...,  9.0969e-01,\n           4.8604e-02,  1.7219e-01],\n         [ 1.8847e+00,  6.4794e-02,  1.6133e-01,  ...,  1.7033e-01,\n          -6.5030e-01,  1.1771e+00],\n         [ 1.1817e+00,  6.8779e-01,  5.2459e-01,  ..., -3.5132e-01,\n          -3.7258e-01, -5.6009e-02]],\n\n        [[ 1.0215e+00,  7.4425e-01,  1.1591e+00,  ...,  2.7391e-01,\n          -2.9277e-01, -1.4802e-01],\n         [ 1.9489e+00,  1.6937e-01,  2.9322e-01,  ...,  6.9300e-01,\n          -1.0268e+00,  3.5865e-01],\n         [ 1.4858e+00,  6.8375e-01,  1.0703e+00,  ...,  7.4776e-01,\n           2.1364e-01,  4.6723e-02],\n         ...,\n         [ 1.9812e+00,  7.7249e-01,  1.1114e+00,  ...,  5.7714e-01,\n          -4.7355e-01,  1.9327e-01],\n         [ 2.0568e+00,  8.3835e-01,  7.9678e-01,  ...,  2.3893e-02,\n          -5.6904e-01,  5.2341e-01],\n         [ 1.2154e+00,  1.3414e+00,  1.0384e+00,  ..., -4.8584e-01,\n           1.6820e-01,  8.4261e-01]],\n\n        [[ 1.4005e+00, -3.9579e-03,  2.6295e-01,  ...,  2.6633e-01,\n          -8.8358e-01,  2.9011e-01],\n         [ 1.5764e+00,  2.6680e-01,  7.0202e-01,  ...,  7.1652e-01,\n          -7.5740e-01,  1.5319e-01],\n         [ 9.2704e-01,  3.3642e-01,  7.9277e-01,  ...,  5.9988e-01,\n          -3.7554e-01, -2.7791e-01],\n         ...,\n         [ 1.3096e+00,  7.1499e-01,  1.1997e+00,  ..., -3.4324e-01,\n          -2.3558e-01, -1.1478e-01],\n         [ 1.6793e+00,  5.9849e-01,  9.4259e-01,  ...,  3.0393e-02,\n          -7.1690e-01, -2.8095e-01],\n         [ 1.8460e+00,  8.6415e-01,  1.0320e+00,  ..., -2.6610e-01,\n          -4.8128e-01,  1.4793e-01]],\n\n        ...,\n\n        [[ 1.6270e+00,  5.1395e-01,  1.5575e+00,  ...,  4.4120e-01,\n           8.6302e-01,  2.7452e-01],\n         [ 1.2132e+00, -5.2067e-02,  6.1256e-01,  ...,  2.4633e-01,\n          -4.6300e-01,  5.4387e-02],\n         [ 1.5218e+00,  2.3298e-01,  1.1459e+00,  ..., -6.5787e-01,\n          -2.7270e-01, -6.9753e-01],\n         ...,\n         [ 2.1243e+00,  1.0449e+00,  1.1757e-01,  ...,  5.7469e-01,\n          -6.2031e-01,  6.1834e-01],\n         [ 1.9299e+00,  7.7909e-01,  1.6217e-01,  ...,  4.4374e-01,\n          -5.3825e-01,  3.7104e-01],\n         [ 1.7415e+00,  1.0361e+00,  5.6567e-01,  ..., -1.5856e-01,\n          -2.6418e-01,  4.7155e-01]],\n\n        [[ 8.2413e-01, -1.4846e-01,  2.9891e-01,  ...,  2.3019e-01,\n           2.7850e-04, -1.0360e-01],\n         [ 1.3581e+00,  2.4826e-01,  2.9452e-01,  ...,  8.4746e-01,\n          -5.0659e-01,  1.1244e+00],\n         [ 1.1608e+00,  9.2114e-01,  9.6576e-01,  ..., -2.1513e-01,\n          -1.1932e+00, -2.6927e-01],\n         ...,\n         [ 7.6091e-01,  4.5270e-01,  4.6338e-01,  ...,  3.5564e-01,\n          -1.0805e+00, -1.1355e+00],\n         [ 1.2467e+00,  1.2111e+00,  1.0467e+00,  ...,  1.3540e-01,\n          -2.1274e-01, -7.5047e-01],\n         [ 6.0060e-01,  9.8755e-01,  7.9962e-01,  ..., -1.2321e-02,\n           2.5219e-01,  1.6050e-01]],\n\n        [[ 1.7934e+00,  7.5683e-01,  4.1987e-01,  ...,  3.7590e-02,\n          -1.4422e-01,  1.1782e-01],\n         [ 2.5753e+00,  3.7607e-01,  8.3770e-01,  ...,  4.5608e-01,\n          -5.3591e-01, -2.3224e-01],\n         [ 1.8376e+00,  3.0043e-01,  1.4269e+00,  ...,  5.1100e-01,\n          -4.1165e-01, -1.5803e-01],\n         ...,\n         [ 1.7462e+00,  7.0657e-01,  6.4432e-01,  ...,  1.2101e+00,\n          -1.7989e-01, -5.2918e-01],\n         [ 2.0691e+00,  5.2253e-01,  1.2977e+00,  ..., -1.9132e-01,\n          -3.9879e-01, -2.6848e-02],\n         [ 1.0723e+00,  7.7057e-01,  6.4880e-01,  ..., -4.1994e-01,\n          -3.8130e-01,  2.6043e-01]]], grad_fn=<NativeLayerNormBackward0>)"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}